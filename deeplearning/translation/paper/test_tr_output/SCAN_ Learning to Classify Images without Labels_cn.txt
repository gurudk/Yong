SCAN：学习对没有标签的图像进行分类

当没有地面实况注释时，我们是否可以自动将图像分组到语义上有意义的集群中？
在计算机视觉中，无监督图像分类的任务仍然是一个重要且开放的挑战。
最近的几种方法试图以端到端的方式解决这个问题。
在本文中，我们偏离了最近的工作，并提出了一种两步走的方法，其中特征学习和聚类是解耦的。
首先，采用表征学习的自监督任务来获取语义有意义的特征。
其次，我们在可学习聚类方法中使用获得的特征作为先验。
在此过程中，我们消除了集群学习依赖于低级特征的能力，这在当前的端到端学习方法中是存在的。
实验评估表明，在分类准确度方面，我们的表现大大优于最先进的方法，特别是在CI-FAR10上为+26.6%，在CIFAR100-20上为+25.0%，在STL10上为+21.3%。
此外，我们的方法是第一个在大规模图像分类数据集上表现良好的方法。
特别是，我们在ImageNet上获得了有希望的结果，并且在不使用任何GroundTruth注解的情况下，在低数据范围内优于几种半监督学习方法。
该代码在此处公开提供。
1 简介和前期工作

图像分类是将预定义的类集中的语义标签分配给图像的任务。
例如，图像描绘了一只猫、一只狗、一辆汽车、一架飞机等，或者进一步抽象了动物、机器等。如今，这项任务通常通过在包含注释图像（即具有相应语义标签的图像）上的大规模数据集[11， 30]上训练卷积神经网络[28， 44， 19， 53， 47]来解决。

在这种监督设置下，网络擅长学习判别性特征表示，这些特征表示随后可以聚类到预定的类中。
但是，当在训练时无法访问真实语义标签时，会发生什么情况？
或者更进一步，语义类别，甚至它们的总数，都不是先验已知的？
在这种情况下，预期的目标是将图像分组到聚类中，以便同一聚类中的图像属于相同或相似的语义类，而不同聚类中的图像在语义上不同。
在这种设置下，无监督或自监督学习技术最近出现在文献中，作为监督特征学习的替代方案。
表征学习方法[13， 39， 58， 35， 16]使用自监督学习仅从图像生成特征表示，省略了对昂贵的语义注释的需求。
为了实现这一点，他们使用预先设计的任务，称为借口任务，这些任务不需要注释数据来学习卷积神经网络的权重。
取而代之的是，视觉特征是通过最小化借口任务的目标函数来学习的。
文献中已经探索了许多借口任务，包括预测补丁上下文 [13， 33] 、修复补丁 [39] 、解决拼图游戏 [35， 37] 、给图像着色 [58， 29] 、使用对抗训练 [14， 15] 、预测噪声 [3] 、计数 [36] 、预测旋转 [16] 、发现伪影 [23] 、生成图像 [41] 、使用预测编码 [38， 20] 、执行实例判别 [51， 18、7、48、32]等。

尽管做出了这些努力，但表征学习方法主要用作两阶段管道的第一个预训练阶段。
第二阶段包括在另一项任务上以完全监督的方式微调网络，最终目标是验证自监督特征转移到新任务的程度。
当缺少注释时，就像这项工作中的情况一样，聚类标准（例如
K-means）仍需要独立定义和优化。
这种做法可以说是次优的，因为它会导致不平衡的集群 [4] ，并且不能保证学习的集群会与语义类对齐。
作为替代方案，端到端学习管道将特征学习与聚类相结合。
第一组方法（例如
DEC [52] ， DAC [6] ， DeepCluster [4] ， DeeperCluster [5] 或其他 [1， 17， 54] ） 利用 CNN 的架构作为聚类图像之前的架构。
从初始特征表示开始，通过从最有信心的样本中导出监督信号 [6， 52] 或通过离线计算的聚类重新分配 [4， 5] 来迭代细化聚类。
第二组方法（例如
IIC [24] ， IMSAT [21] ）提出通过最大化图像与其增强之间的互信息来学习聚类函数。
一般来说，依赖于网络初始特征表示的方法对初始化敏感 [6， 52， 4， 5， 22， 17， 54] ，或者容易产生退化解 [4， 5]，因此需要特殊的机制（例如
预训练、集群重新分配和特征清理）以避免这些情况。
最重要的是，由于集群学习依赖于网络初始化，因此它们可能会锁定低级特征，例如颜色，这对于语义聚类的目标来说是不需要的。
为了部分缓解这一问题，一些作品[24,21,4]与特定预处理的使用有关（例如
Sobel 滤波）。
在这项工作中，我们提倡采用两步法进行无监督图像分类，这与最近的端到端学习方法形成鲜明对比。
所提出的方法名为SCAN（Semantic Clustering by Adoption Nearest Neighbors），它利用了表示和端到端学习方法的优点，但同时也解决了它们的缺点：
-第一步，我们通过一个借口任务来学习特征表示。
与在学习特征表示后需要K-means聚类的表示学习方法相比，这会导致聚类简并[4]，我们建议根据特征相似性挖掘每个图像的最近邻。
我们实证地发现，在大多数情况下，这些最近邻属于同一语义类（见图2），使它们适用于语义聚类。
-在第二步中，我们将语义上有意义的最近邻作为先验集成到可学习的方法中。
我们通过使用损失函数将每张图像及其挖掘的邻居分类在一起，该损失函数在softmax之后最大化其点积，从而推动网络产生一致和判别性（一热）预测。
与端到端方法不同，学习的集群依赖于更有意义的特征，而不是网络架构。
此外，因为我们鼓励最近邻的不变性，而不仅仅是 w.r.t.
增强，我们发现没有必要对输入应用特定的预处理。
实验评估表明，我们的方法在多个数据集上都大大优于以前的工作。
此外，我们报告了在大规模ImageNet数据集上取得的有希望的结果。
这验证了我们的假设，即与最近的端到端工作相比，分离学习（语义上有意义的）特征并将它们聚类可以说是一种更好的方法。
2 方法

以下各节介绍了我们方法的基石。
首先，我们展示了如何从借口任务中挖掘最近邻作为语义聚类的先验。
此外，我们还引入了额外的约束来选择适当的借口任务，这些任务能够产生语义上有意义的特征表示。
其次，我们将获得的先验结果集成到一个新的损失函数中，以将对每个图像及其最近的邻居进行分类。
此外，我们还展示了如何通过自标记方法缓解最近邻选择中固有的噪声问题。
我们认为，这些贡献中的每一个都与无监督图像分类有关。
2.1 语义聚类的表示学习

在监督学习设置中，每个样本都可以使用可用的真值标签与其正确的聚类相关联。
特别是，图像 D = X 1 之间的映射 ， . . .
， X |D|语义类C通常可以通过最小化交叉熵损失来学习。

然而，当我们无法访问这种地面实况标签时，我们需要定义一个先验，以获得哪些样本可能属于一起，哪些不是。
端到端学习方法利用CNN的架构作为先验[54,6,52,17,4,5]，或强制图像与其增强之间的一致性[24,21]来解开聚类。
在这两种情况下，已知集群学习对网络初始化很敏感。
此外，在训练开始时，网络尚未从图像中提取高级信息。
因此，集群可以很容易地锁定到低级特征（例如
颜色、纹理、对比度等），这对于语义聚类来说是次优的。
为了克服这些限制，我们采用表示学习作为一种手段，以获得更好的语义聚类先验。
在表示学习中，借口任务 τ 以自监督的方式学习嵌入函数 Φ θ - 由权重为 θ 的神经网络参数化 - 将图像映射到特征表示中。
文献提供了几个借口任务，可用于学习这样的嵌入函数 Φ θ（例如
旋转预测 [16] 、仿射或透视变换预测 [57] 、着色 [29] 、绘画中 [39] 、实例判别 [51、18、7、32] 等）。
然而，在实践中，某些借口任务基于特定的图像转换，导致学习到的特征表示与所采用的变换相变。
例如，当 Φ θ 预测仿射变换的变换参数时，同一图像的不同仿射变换将导致 Φ θ 的不同输出预测。
这使得学习到的特征表示不太适合语义聚类，在语义聚类中，特征表示应该对图像转换保持不变。
为了克服这个问题，我们施加了借口任务 τ 来最小化图像 X i 与其增强 T [X i ] 之间的距离，可以表示为：
因此，可以使用任何满足等式 1 的借口任务 [51， 18， 7， 32]。
例如，图1显示了在满足公式1的实例判别任务[51]下检索最近邻时的结果。
我们观察到，相似的特征被分配给语义相似的图像。
使用不同借口任务的实验评估可以在第 3.2 节中找到。
为了理解为什么具有相似高级特征的图像通过 Φ θ 更紧密地映射在一起，我们进行了以下观察。
首先，借口任务输出以图像为条件，迫使 Φ θ 从其输入中提取特定信息。
其次，由于 Φ θ 的容量有限，因此它必须从其输入中丢弃无法预测高级借口任务的信息。
例如，Φ θ 不太可能通过仅编码颜色或输入图像中的单个像素来解决实例判别任务。
因此，在Φθ的嵌入空间中，具有相似高级特性的图像将更紧密地位于一起。
我们得出的结论是，来自表征学习的借口任务可用于获得语义上有意义的特征。
根据这一观察结果，我们将利用借口特征作为对图像进行聚类的先验。
2.2 语义聚类丢失

挖掘最近的邻居。
在第 2.1 节中，我们提出可以使用表征学习的借口任务来获得语义上有意义的特征。
然而，天真地对获得的特征应用K-means会导致聚类简并[4]。
判别模型在学习决策边界时，可以将其所有概率质量分配给同一聚类。
这导致一个集群主导其他集群。
相反，我们选择了更好的策略。
让我们首先考虑以下实验。
通过表示学习，我们在未标记的数据集D上训练模型Φθ，以解决一个借口任务τ，即实例判别[7,18]。
然后，对于每个样本 X i ∈ D，我们在嵌入空间 Φ θ 中挖掘其 K 最近邻。
我们将集合 N 习定义为数据集 D 中 X i 的相邻样本，图 2 量化了挖掘的最近邻是同一语义簇的实例的程度。
我们观察到，在四个数据集 1 （CIFAR10 [27] ， CIFAR100-20 [27] ， STL10 [9] 和 ImageNet [11] ） 中，对于不同的 K 值，情况大致如此。
损失函数。
我们的目标是学习一个聚类函数 Φ η - 由权重为 η 的神经网络参数化 - 将样本 X i 及其挖掘的邻居 N 习 一起分类。
函数 Φ η 终止于 softmax 函数，以对聚类 C = {1， . .
， C}， Φ η （X i ） ∈ [0， 1] C .
样本 X i 被分配到聚类 c 的概率表示为 Φ c η （X i）。
我们通过最小化以下目标来学习 Φ η 的权重：
这里， • 表示点积运算符。
等式 2 中的第一个项施加了 Φ η，以便对样本 X i 及其相邻样本 N 习 做出一致的预测。
请注意，当预测为一热（置信）并分配给同一聚类（一致）时，点积将是最大的。
为了避免 Φ η 将所有样本分配给单个聚类，我们加入了一个熵项（等式 2 中的第二个项），它将预测均匀地分布在聚类 C 中。如果事先知道聚类 C 上的概率分布，而这里的情况并非如此，则该术语可以用 KL 散度代替。

请记住，C 语言中簇的确切数量通常是未知的。
然而，与之前的工作[52,6,24]类似，我们选择C等于地面实况聚类的数量进行评估。
在实践中，应该可以粗略估计聚类 2 的数量。
根据这个估计，我们可以将聚类过度聚类到更多的聚类，并强制类分布均匀。
我们参考第 3.4 节进行具体实验。
实施详细信息。
为了实际实现我们的损失函数，我们通过对足够大的批次进行采样来近似数据集统计数据。
在训练过程中，我们随机增强样本 X i 和它们的邻居 N 习。
对于极端情况 K = 0，仅要求样本及其增强之间存在一致性。
我们将 K 设置为 ≥ 1 以捕获更多的聚类方差，但代价是引入噪声，即并非所有样本及其邻居都属于同一聚类。
第 3.2 节实验表明，与仅加强样本及其增强之间的一致性相比，选择 K ≥ 1 可显着改善结果，如 [24， 21] 所示。
讨论。
与 [40， 25， 49， 2， 34， 59， 52] 不同，我们没有在损失中包含重建标准，因为我们的目标任务没有明确要求这样做。
毕竟，我们只对从输入信号编码的几位信息感兴趣，而不是重建准则通常需要的大部分信息。
值得注意的是，我们案例中的一致性是通过损失中的点积项在单个样本的水平上实现的，而不是基于类中联合分布的近似值 [24， 21] 。
我们认为，这种选择允许以更直接的方式表达一致性。
2.3 通过自标签进行微调

第 2.2 节中的语义聚类损失在样本与其邻居之间施加了一致性。
更具体地说，每个样本都与 K ≥ 1 个邻居相结合，其中一些不可避免地不属于同一个语义簇。
这些假阳性示例会导致网络不太确定的预测。
同时，我们通过实验观察到，具有高度置信度预测（p max ≈ 1）的样本往往被分类到适当的聚类。
事实上，网络在聚类过程中形成的高度置信度的预测可以看作是每个类的“原型”（参见第 3.5 节）。
与之前的工作[6,4,52]不同，这使我们能够以更可靠的方式根据预测的置信度选择样本。
因此，我们提出了一种自标记方法[43,31,46]，特别是在训练过程中，通过对输出处的概率进行阈值化来选择置信样本，即p最大值>阈值。
对于每个置信度的样本，通过将样本分配给其预测的聚类来获得伪标签。
交叉熵损失用于更新获得的伪标签的权重。
为了避免过拟合，我们计算了置信样本的强增强版本的交叉熵损失。
自标记步骤允许网络自我纠正，因为它逐渐变得更加确定，将更多样本添加到混合物中。
我们参考第 3.2 节进行具体实验。
算法1总结了所提方法的所有步骤。
我们进一步将其称为 SCAN，即
通过采用最近邻进行语义聚类。
3 实验

3.1 实验装置

数据。
在CIFAR10 [27] ， CIFAR100-20 [27] ， STL10 [9] 和 ImageNet [11] 上进行实验评估。
我们首先关注较小的数据集。
ImageNet 上的结果将在第 3.5 节中单独讨论。
一些先前的工作[24,6,52,54]在完整的数据集上进行了训练和评估。
不同的是，我们分别使用 train 和 val split 进行训练和评估。
这样做，可以研究该方法的泛化特性，以获得新的看不见的例子。
请注意，与以前的工作相比，这不会带来任何不公平的优势。
结果报告为 10 次不同运行的平均值和标准差。
最后，所有实验都使用相同的主干、增强、借口任务和超参数进行。
培训设置。
我们使用标准的 ResNet-18 主干网。
对于每个样本，通过基于噪声对比估计（NCE）[51]的实例判别任务确定20个最近邻。
我们采用SimCLR [7]实现在较小的数据集上执行实例判别任务，并在ImageNet上采用MoCo [8]的实现。
选定的借口任务满足公式 1 中的特征不变性约束，即应用于增强输入图像的变换。
具体而言，每个图像都被解缠为一个独立于应用变换的唯一实例。
为了加快训练速度，我们转移了从借口任务中获得的权重，以启动聚类步骤（第 2.2 节）。
我们使用大小为 128 的批次执行 100 个 epoch 的聚类步骤。
熵项的权重设置为 λ = 5。
较高的重量可避免在训练期间早期对样本进行过早分组。
结果似乎对λ的微小变化不敏感。
在聚类步骤之后，我们使用阈值为 0.99 的自标记过程（第 2.3 节）训练另外 200 个 epoch。
加权交叉熵损失补偿了聚类间置信样本之间的不平衡。
类权重与阈值化后的批次中出现的次数成反比。
网络权重通过Adam[25]更新，学习率为10 -4，权重衰减为10 -4。
在聚类和自标记步骤中，通过组成来自RandAugment [10]的四个随机选择的变换，这些图像得到了强烈的增强。
变换参数在固定间隔之间均匀采样。
有关详细信息，请访问补充材料。
验证标准 在聚类步骤中，我们根据最低损失选择最佳模型。
在自标记步骤中，当置信样本的数量趋于稳定时，我们保存了模型的权重。
我们遵循这些做法，因为我们无法访问标记的验证集。
3.2 消融研究

方法。
我们通过对CIFAR10的消融研究，量化了我们方法的不同部分的性能增益，如表1所示。
NCE 借口特征的 K 均值聚类导致的准确率最低 （65.9%），并且其特征是方差大 （5.7%）。
这是意料之中的，因为聚类分配可能不平衡（图 3），并且不能保证与真值类对齐。
有趣的是，将 K 均值应用于借口特征优于以前最先进的基于端到端学习方案的无监督分类方法（参见第 3.3 节）。
这一观察结果支持了我们的主要主张，即将特征学习与聚类分开是有益的。
通过 SCAN 损失更新网络权重，同时通过 SimCLR 转换增强输入图像，其性能优于 K-均值 （+15.9%）。
请注意，扫描损失在某种程度上与 K 均值有关，因为这两种方法都使用借口特征作为它们在聚类图像之前。
不同的是，我们的损失避免了集群退化问题。
我们还研究了在训练期间使用不同增强策略的效果。
将 RandAgument （RA） 的变换应用于样本及其开采的邻居可进一步提高性能 （78.7% vs. 81.8%）。
我们假设，强增强通过施加额外的不变性来帮助减小解空间。
通过自标记对网络进行微调可进一步提高集群分配的质量（81.8%至87.6%）。
在自标记过程中，网络会随着逐渐变得更加自信而自我纠正（参见图 4）。
重要的是，为了成功应用自标记，需要改变增强方式（见表1或图5）。
我们假设这是必要的，以防止网络在已经分类良好的样本上过拟合。
最后，图 6 显示自标记程序对阈值的值不敏感。
借口任务。
我们研究了使用不同的借口任务来挖掘最近邻居的效果。
具体而言，我们考虑了之前的实例判别任务的两种不同实现 [51， 7] 和 RotNet [16] 。
后者训练网络预测图像旋转。
因此，在通过 RotNet 预训练的模型的嵌入空间中，图像 X i 与其增强 T [X i ] 之间的距离并未最小化（参见公式 1）。
不同的是，实例区分任务在所使用的增强中满足不变性准则。
表 2 显示了 CIFAR10 的结果。
首先，我们观察到所提出的方法与特定的借口任务无关。
所有病例均报告准确率高（> 70%）。
其次，满足不变性准则的借口任务更适合挖掘最近邻，即 inst 的 83.5% 和 87.6%。
discr。
而 RotNet 为 74.3%。
这证实了我们在第 2.1 节中的假设，即选择一个在图像及其增强之间施加不变性的借口任务是有益的。
对 K 的值敏感，甚至在将 K 增加到 50 时保持稳定。
这是有益的，因为我们不必在非常新的数据集上微调 K 的值。
事实上，当将 K 的值增加到某个值时，鲁棒性和准确性都会提高。
我们还考虑了极端情况 K = 0，当仅对图像及其增强执行一致的预测时。
与 K = 5 相比，所有三个数据集的性能均有所下降，CIFAR10 为 56.3% 和 79.3%，CIFAR100-20 为 24.6% 和 41.1%，STL10 为 47.70% 和 69.8%。
这证实了通过在样本与其最近邻之间实施连贯的预测，可以学习到更好的表示。
邻居数。

收敛。图 8 显示了从最近邻（即属于不同类别的样本对）中删除假阳性时的结果。

从分类精度的角度来看，研究结果可以看作是所提方法的上限。
一个理想的特性是，簇能快速与地面实况对齐，在 CIFAR10 和 STL10 上获得接近完全监督的性能，而使用的邻居 K 的数量增加相对较小。
与 CIFAR100-20 相比，性能改进较低，可以用用于测量准确性的超类的模糊性来解释。
例如，没有一种方法可以将杂食动物或食肉动物等类别归为一类。
3.3 与最新技术的比较

比较。
表3在三个不同的基准上将我们的方法与最先进的方法进行了比较。
我们根据聚类准确性 （ACC）、归一化互信息 （NMI） 和调整后的兰特指数 （ARI） 评估结果。
所提出的方法在所有三个指标上都大大优于以前的工作，例如
CIFAR10 准确度为 +26.6%，CIFAR100-20 为 +25.0%，STL10 为 +21.3%。
我们还与最先进的表征学习 [7] （Pretext + K-means） 进行了比较。
如第3.2节所示，我们的方法在借口特征上优于K-means的应用。
最后，在以完全监督的方式解决问题时，我们还包括结果。
我们的模型在 CIFAR-10 和 STL-10 上获得了接近监督的性能。
由于使用了超类，CIFAR100-20 的性能差距更大。
其他优点。
与之前的工作[6,24,21]相比，我们不需要进行任何特定于数据集的微调。
此外，CIFAR10 上的结果可以在 6 小时内在单个 GPU 上获得。
相比之下，从 [24] 训练模型至少需要一天的训练时间。
3.4 过度聚集

到目前为止，我们假设已经了解了地面实况类的数量。
使用匈牙利匹配算法评估方法预测。
但是，如果聚类的数量不再与地面实况类的数量匹配，会发生什么情况。
表 3 报告了当我们高估了 2 倍的地面实况类数量时的结果，例如
我们将CIFAR10分为 20 个类，而不是 10 个类。
CIFAR10（87.6%至86.2%）和STL10（76.7%至76.8%）的分类准确率保持稳定，CIFAR100-20（45.9%至55.1%）的分类准确率有所提高3。
我们得出的结论是，该方法不需要了解集群的确切数量。
我们假设 CIFAR100-20 的性能提高与更高的类内方差有关。
更具体地说，CIFAR100-20 将多个对象类别分组到超类中。
在这种情况下，过度聚类更适合解释类内方差。
表 4：来自 ImageNet 的 50、100 和 200 个随机选择类的验证集结果。
K-means的结果是使用MoCo [8]的借口特征获得的。
我们提供了在聚类步骤（*）和自标记步骤（†）之后通过我们的方法获得的结果。
3.5 图像网络

设置。
我们考虑了大规模ImageNet数据集上的无监督图像分类问题[11] 。
我们首先考虑 50、100 和 200 个随机选择类的较小子集。
50 和 100 类的集合分别是 100 和 200 类的子集。
有关培训设置的更多详细信息，请参阅补充材料。
定量评估。
表 4 将我们的结果与在 MoCo [8] 的借口特征上应用 Kmeans 的结果进行了比较。
令人惊讶的是，K-means的应用已经在这项具有挑战性的任务上表现出色。
我们得出的结论是，借口特征非常适合语义聚类的下游任务。
使用 SCAN-loss 训练模型的性能再次优于 K-means 的应用。
此外，当通过自标记对模型进行微调时，结果得到了进一步的改善。
我们不包括先前最先进的数字 [24] ，因为我们在运行公开可用的代码时无法在 ImageNet 上获得令人信服的结果。
我们建议读者参阅补充材料，以获取有关ImageNet-50的更多定性结果。
原型行为。
在使用 SCAN 损失训练模型后，我们可视化了不同的聚类。
具体来说，我们发现每个聚类中最接近前 10 个最有信心的样本的平均嵌入。
结果与匹配的真值类的名称一起显示在图 9 中。重要的是，我们观察到发现的样本与数据集的类别非常对齐，除了“双簧管”和“鳄梨酱”（红色）。

此外，每个物体类别的区分特征都清楚地存在于图像中。
因此，我们将获得的样本视为各种集群的“原型”。
请注意，执行的实验与原型网络[45]非常吻合。
ImageNet -1000 类。
最后，在完整的Im-ageNet数据集上训练模型。
图 11 显示了来自验证集的图像，这些图像由我们的模型分配给同一聚类。
有意义，例如
飞机、汽车和灵长类动物。
此外，这些集群还捕获了各种不同的背景、视点等。
我们得出的结论是，（在很大程度上）模型预测对图像特征是不变的，图像特征不会改变语义。
另一方面，根据 ImageNet 地面实况注释，并非所有样本对都应该分配给同一聚类。
例如，真值注释区分了不同的灵长类动物，例如
黑猩猩、狒狒、叶猴等
我们认为，在ImageNet的情况下，没有一种正确的方法可以根据图像的语义对图像进行分类。
即使对于人工注释者来说，在没有先验知识的情况下根据 ImageNet 类对每个图像进行聚类也不是简单的。
根据 ImageNet 层次结构，我们选择以下超类的类实例：狗、昆虫、灵长类动物、蛇、衣服、建筑物和鸟类。
图 10 显示了所选类别的混淆矩阵。
混淆矩阵具有块对角线结构。
结果表明，错误分类的样本倾向于被分配给同一超类内的其他聚类，例如，该模型混淆了两种不同的犬种。
我们得出的结论是，该模型已经学会了将具有相似语义的图像组合在一起，而其预测错误可以归因于缺乏注释，这可能会解开某些类别之间的细粒度差异。
最后，表5将我们的方法与使用1%的图像作为标记数据时的最新半监督学习方法进行了比较。
我们在ImageNet上获得了以下定量结果：Top-1：39.9%，Top-5：60.0%，NMI：72.0%，ARI：27.5%。
我们的方法在不使用标签的情况下优于几种半监督学习方法。
这进一步证明了我们方法的力量。
[51] ResNet-50 -39.2 BigBiGAN [15] ResNet-50（4x） -55.2 PIRL [32] ResNet-50 -57.2 CPC v2 [20] ResNet-161 52.7 77.9 SimCLR [7] ResNet-50 48.3 75.5
SCAN（我们的）

ResNet-50 39.9 60.0
4 结论

我们提出了一种新的无监督图像分类框架。
与最近采用端到端策略的工作相比，所提出的方法具有几个优点。
实验评估表明，所提方法在多种数据集上均优于前人。
此外，ImageNet上的积极结果表明，语义聚类可以应用于大规模数据集。
受到这些发现的鼓舞，我们认为我们的方法允许对其他领域的一些扩展，例如
语义分割、半监督学习和少样本学习。
B 图像网

B.1 培训设置

下面我们总结了 ImageNet 的训练设置。
借口任务 类似于我们在较小数据集上的设置，我们选择歧视作为我们的借口任务。
具体来说，我们使用 MoCo [8] 的实现。
我们使用 ResNet-50 模型作为骨干网。
聚类

步骤：我们在聚类步骤中冻结主干网权重，并且仅使用 SCAN 损失训练最终的线性层。
更具体地说，我们并行训练 10 个独立的线性头。
当开始自我标记步骤时，我们选择损失最小的头部继续进行训练。
每张图像都使用 SimCLR [7] 的增强技术进行增强。
我们重用之前的熵权 （5.0），分别在 50、100 和 200 类的子集上使用大小为 512、1024 和 1024 的批次进行训练。
我们使用动量为 0.9 和初始学习率为 5.0 的 SGD 优化器。
该模型经过 100 个时期的训练。
在完整的 ImageNet 数据集上，我们将批大小和学习率分别增加到 4096 和 30.0，并将邻居数量减少到 20 个。
自我标签

步骤：我们使用 RandAugment 的强大增强功能，通过自我标记来微调权重。
使用 SGD 和动量 0.9 更新了 25 个时期的模型权重。
初始学习率设置为 0.03 并保持不变。
使用大小为 512 的批次。
重要的是，模型权重通过指数移动平均线进行更新，α = 0.999。
我们发现没有必要在交叉熵损失中应用类平衡。
B.2 ImageNet 子集

混淆矩阵 图 S3 显示了 ImageNet-50 数据集上的混淆矩阵。
大多数错误都可以在难以解开的类别中找到，例如：
“巨型雪纳瑞犬”和“扁平毛猎犬”都是黑狗品种，“鳄梨酱”和“土豆泥”都是食物等。
原型示例 图 S4 显示了 ImageNet-50 子集上每个集群的原型图像。
此图扩展了正文中的图 9。
值得注意的是，绝大多数原型图像都可以与其中一个地面实况类进行匹配。
低置信度示例 图 S5 显示了模型对 ImageNet-50 子集生成低置信度预测的示例。
在许多情况下，低置信度输出可以归因于场景中有多个对象可见。
其他情况可以通过对象的部分可见性、场景中分散注意力的元素或感兴趣对象的模糊性来解释。
B.3 ImageNet -完整版

我们在完整的ImageNet数据集上包含了额外的定性结果。
具体而言，图 S6、S7 和 S8 显示了分配给同一集群的验证集中的图像。
这些可以与主要论文中的图 11 一起查看。
此外，我们在图 S9 中显示了一些错误。
当模型过于关注背景，或者当网络无法轻松区分成对看起来相似的图像时，就会发生失败情况。
然而，在大多数情况下，我们仍然可以为集群附加一些语义意义，例如
笼子里的动物，白色的栅栏。
C 实验装置

C.1 数据集

与之前的工作[24,6,52,54]不同，我们没有在完整的数据集上进行训练和评估。
不同的是，我们使用标准的 train-val 分裂来研究模型的泛化特性。
此外，我们还报告了较小数据集的平均值和标准差。
我们希望鼓励今后的工作也采用这一程序。
表 S1 概述了所用数据集的类数、图像数量和纵横比。
可以在我们的 git 仓库中找到 ImageNet-50、ImageNet-100 和 ImageNet-200 上的选定类。
图1：图像（第一列）及其最近邻（其他列）[51]。
图 2：相邻样本往往是同一语义类的实例。
图 3：K 均值聚类分配不平衡。
图6：自标记步骤中的消融阈值。
图9：通过对置信样本进行采样获得的原型。
图 11：我们的模型在 ImageNet 上提取的聚类（更多补充）。
图 S2：低置信度预测。
它们是：仅部分可见、被遮挡、在恶劣的照明条件下等。
图S3：ImageNet-50上的混淆矩阵。
图 S6： ImageNet-1000 的示例集群 （1）。
图 S7： ImageNet-1000 的示例簇 （2）。
图 S8： ImageNet-1000 的示例集群 （3）。
图 S9： 我们的模型预测的 ImageNet-1000 集群不正确。
利用已经分类良好的示例，并纠正由于嘈杂的最近邻居而导致的错误。算法 1 采用最近邻 （SCAN） 1 的语义聚类：输入：数据集 D、聚类 C、任务 τ、神经网络 Φ θ 和 Φη，邻域 ND = {}。

2：使用任务 τ 优化 Φ θ。
消融方法 CIFAR10
消融借口 CIFAR10
最先进的比较：我们报告了聚类 （ * ） 和自标记步骤 （ †） 后 10 次不同运行的平均结果，以及最佳模型。
与之前的工作相反，我们分别使用 train 和 val split 进行训练和评估，而不是使用完整的数据集进行训练和测试。
得到的聚类在语义上是
与使用 ImageNet 上 1% 的标记数据的监督学习和半监督学习方法进行比较。
数据集概述
