DEFORMABLE DETR：用于端到端物体检测的可变形变压器

最近有人提出 DETR 来消除物体检测中对许多手工设计组件的需求，同时表现出良好的性能。
然而，由于Transformer注意力模块在处理图像特征图时存在局限性，因此该算法存在收敛速度慢、特征空间分辨率有限的问题。
为了缓解这些问题，我们提出了 Deformable DETR，其注意力模块只关注参考周围的一小部分关键采样点。
可变形 DETR 可以获得比 DETR 更好的性能（尤其是在小物体上），训练周期少 10×。
在COCO基准上的广泛实验证明了我们方法的有效性。
代码于 https:// github.com/fundamentalvision/Deformable-DETR 发布。
1 引言

现代物体检测器采用许多手工制作的组件（Liu et al.， 2020），例如锚点生成、基于规则的训练目标分配、非最大抑制 （NMS） 后处理。
它们不是完全端到端的。
最近，Carion et al. （2020） 提出了 DETR 来消除对此类手工制作组件的需求，并构建了第一个完全端到端的物体检测器，取得了非常有竞争力的性能。
DETR 通过结合卷积神经网络 （CNN） 和 Transformer （Vaswani et al.， 2017） 编码器-解码器，利用简单的架构。
他们利用 Transformer 的多功能和强大的关系建模功能，在正确设计的训练信号下替换手工制定的规则。
尽管 DETR 的设计有趣且性能良好，但它也有自己的问题：（1） 与现有的目标检测器相比，它需要更长的训练周期才能收敛。
例如，在 COCO （Lin et al.， 2014） 基准上，DETR 需要 500 个 epoch 才能收敛，这比 Faster R-CNN （任 et al.， 2015） 慢约 10 到 20 倍。
（ 2 ） DETR 在检测小物体方面的性能相对较低。
现代目标检测器通常利用多尺度特征，其中从高分辨率特征图中检测到小物体。
同时，高分辨率特征图导致 DETR 的复杂性令人无法接受。
上述问题主要可归因于Transformer组件在处理图像特征图时的不足。
在初始化时，注意力模块将几乎均匀的注意力权重投射到特征图中的所有像素。
长时间的训练周期对于学习注意力权重以专注于稀疏有意义的位置是必要的。
另一方面，Transformer 编码器中的注意力权重计算是二次计算的。
像素数。
因此，处理高分辨率特征图具有非常高的计算和内存复杂性。
在图像域中，可变形卷积（Dai et al.， 2017）是一种强大而有效的机制，可以处理稀疏的空间位置。
它自然避免了上述问题。
虽然它缺乏元素关系建模机制，而元素关系建模机制是DETR成功的关键。
在本文中，我们提出了可变形的DETR，以缓解DETR收敛缓慢和复杂度高的问题。
它结合了可变形卷积的稀疏空间采样和 Transformer 的关系建模能力的优点。
我们提出了可变形的注意力模块，该模块关注一小群采样位置，作为所有特征图像素中突出关键元素的预过滤器。
该模块可以自然地扩展到聚合多尺度特征，而无需 FPN 的帮助（Lin et al.， 2017a）。
在Deformable DETR中，我们利用（多尺度）可变形注意力模块来替换Transformer注意力模块处理特征图，如图1所示。
可变形 DETR 为我们利用端到端目标检测器的变体提供了可能性，这要归功于其快速收敛、计算和内存效率。
我们探索了一种简单有效的迭代边界框细化机制来提高检测性能。
我们还尝试了一个两阶段的 Deformable DETR，其中区域提案也由大量 Deformable DETR 生成，这些建议被进一步输入到解码器中以进行迭代边界框细化。
对COCO（Lin等人，2014）基准的广泛实验证明了我们方法的有效性。
与 DETR 相比，Deformable DETR 可以以更少的训练周期获得更好的性能（尤其是在小物体上），训练周期少 10×。
所提出的两级可变形DETR变体可以进一步提高性能。
代码于 https://github 发布。
com/fundamentalvision/Deformable-DETR.
2 相关工作

高效的注意力机制。
变压器（Vaswani et al.， 2017）涉及自我关注和交叉关注机制。
Transformers 最广为人知的问题之一是在大量关键元素数量下具有很高的时间和内存复杂性，这在许多情况下阻碍了模型的可扩展性。
最近，已经做出了许多努力来解决这个问题（Tay et al.， 2020b），在实践中可以大致分为三类。
第一类是在键上使用预定义的稀疏注意模式。
最直接的范式是将注意力模式限制为固定的本地窗口。
大多数作品（Liu et al.， 2018a;Parmar 等人，2018 年;Child 等人，2019 年;Huang 等人，2019 年;Ho 等人，2019 年;Wang等人，2020a;胡等，2019;Ramachandran 等人，2019 年;Qiu et al.， 2019;Beltagy 等人，2020 年;Ainslie 等人，2020 年;Zaheer et al.， 2020） 遵循这种范式。

尽管将注意力模式限制在局部社区可以降低复杂性，但它会丢失全局信息。
为了补偿，Child et al. （2019） ;Huang et al. （2019） ;Ho et al. （2019） ;Wang et al. （2020a） 在固定的时间间隔参加关键元素，以显着增加键上的感受野。

Beltagy 等人 （2020） ;Ainslie 等人 （2020） ;Zaheer et al. （2020） 允许少数特殊代币访问所有关键元素。

Zaheer 等人 （2020） ;Qiu et al. （2019） 还添加了一些预先固定的稀疏注意力模式，以直接参与远处的关键元素。

第二类是学习依赖于数据的稀疏注意力。
Kitaev et al. （2020） 提出了一种基于局部敏感哈希 （LSH） 的注意力，该注意力将查询和关键元素都散列到不同的箱中。
Roy et al. （2020） 也提出了类似的想法，其中 k-means 找出最相关的键。
Tay et al. （2020a） 学习块排列以实现块级稀疏注意力。
第三类是探索自我注意中的低秩属性。
Wang et al. （2020b） 通过在尺寸维度而不是通道维度上进行线性投影来减少关键元素的数量。
Katharopoulos 等人 （2020） ;Choromanski et al. （2020） 通过核化近似改写了自注意力的计算。

在图像领域，高效注意力机制的设计（例如，Parmar et al. （2018） 2019）承认，由于内存访问模式的固有限制，这种方法在实现上比具有相同FLOPs的传统卷积慢得多（至少慢3×慢）。
另一方面，正如Zhu et al. （2019a）所讨论的，卷积存在变体，例如可变形卷积（Dai et al.， 2017;Zhu et al.， 2019b） 和动态卷积 （Wu et al.， 2019） ，这也可以看作是自我注意机制。

特别是，可变形卷积在图像识别中的作用比Transformer自注意力更有效和高效。
同时，它缺乏元素关系建模机制。
我们提出的可变形注意力模块受到可变形卷积的启发，属于第二类。
它只关注从查询元素的特征预测的一小组固定的采样点。
与Ramachandran et al. （2019）不同;胡等人（2019）在相同的FLOPs下，可变形的注意力只是比传统的卷积略慢。

用于目标检测的多尺度特征表示。
目标检测的主要困难之一是有效地表示不同尺度的对象。
现代物体检测器通常利用多尺度特征来适应这一点。
作为开创性的工作之一，FPN（Lin et al.， 2017a）提出了一种自上而下的路径来结合多尺度特征。
PANet（Liu et al.， 2018b）在FPN的顶部进一步增加了一个自下而上的路径。
Kong等人（2018）通过全局注意力操作结合了所有尺度的特征。
Zhao et al. （2019）提出了一种U形模块来融合多尺度特征。
最近，NAS-FPN（Ghiasi et al.， 2019）和Auto-FPN（Xu et al.， 2019）被提出通过神经架构搜索自动设计跨尺度连接。
Tan et al. （2020） 提出了 BiFPN，它是 PANet 的重复简化版本。
我们提出的多尺度可变形注意力模块可以通过注意力机制自然聚合多尺度特征图，而无需这些特征金字塔网络的帮助。
3 重新审视变压器和 DETR

变压器中的多头关注。
Transformers（Vaswani et al.， 2017）是一种基于机器翻译注意力机制的网络架构。
给定一个查询元素（例如，输出句子中的目标词）和一组关键元素（例如，输入句子中的源词），多头注意力模块根据衡量查询键对兼容性的注意力权重自适应聚合键内容。
为了让模型能够关注来自不同表示子空间和不同位置的内容，不同注意力头的输出用可学习的权重线性聚合。
设 q ∈ Ω q 索引具有表示特征 z 的查询元素 q ∈ R C ，k ∈ Ω k 索引具有表示特征 x k ∈ R C 的关键元素，其中 C 是特征维度，Ω q 和 Ω k 分别指定查询和关键元素的集合。
然后，多头注意力特征的计算公式为：
其中 m 索引注意力头，W m ∈ R Cv×C 和 W m ∈ R C×Cv 具有可学习的权重
} 被归一化为
Cv×C 也是可学习的权重。
为了消除不同空间位置的歧义，表示特征 z q 和 x k 通常是元素内容和位置嵌入的串联/求和。
Transformer 存在两个已知问题。
一是变形金刚在融合之前需要很长的培训计划。
假设查询和关键元素的数量分别为 N q 和 N k 。
通常，通过适当的参数初始化，U m z q 和 V m x k 遵循均值为 0 和方差为 1 的分布，这使得注意力权重 A mqk ≈ 1 N k ，当 N k 大时。
这将导致输入要素的梯度不明确。
因此，需要很长的训练计划，以便注意力权重可以集中在特定键上。
在图像域中，关键元素通常是图像像素，N k可能非常大，收敛性很繁琐。
另一方面，多头注意力的计算和内存复杂度可能非常高，需要大量的查询和关键元素。
方程1的计算复杂度为：
在图像域中，查询和关键元素均为像素，N q = N k C，复杂度由第三项主导，如O（N q N k C）。
因此，多头注意力模块随着特征图大小的变化而遭受二次复杂度增长。
DETR。
DETR （Carion et al.， 2020） 建立在 Transformer 编码器-解码器架构之上，结合了基于集合的匈牙利损失，通过二分匹配强制对每个地面实况边界框进行唯一预测。
我们简要回顾一下网络架构如下：
给定由 CNN 主干网提取的输入特征图 x ∈ R C×H×W（例如，ResNet （He et al.， 2016）），DETR 利用标准的 Transformer 编码器-解码器架构将输入特征图转换为一组对象查询的特征。
在目标查询特征（由解码器生成）之上添加三层前馈神经网络（FFN）和线性投影作为检测头。
FFN 充当回归分支来预测边界框坐标 b ∈ [0， 1] 4 ，其中 b = {b x ， b y ， b w ， b h } 编码归一化框中心坐标、框的高度和宽度（相对于图像大小）。
线性投影充当分类分支以生成分类结果。
对于 DETR 中的 Transformer 编码器，查询元素和关键元素都是特征图中的像素。
输入是 ResNet 特征图（具有编码的位置嵌入）。
设 H 和 W 分别表示特征图的高度和宽度。
自注意力的计算复杂度为O（H 2 W 2 C），随空间大小呈二次增长。
对于 DETR 中的 Transformer 解码器，输入包括来自编码器的特征图，以及由可学习位置嵌入表示的 N 个对象查询（例如，N = 100）。
解码器中有两种类型的注意力模块，即交叉注意力模块和自注意力模块。
在交叉注意力模块中，对象查询从特征图中提取特征。
查询元素属于对象查询，关键元素属于编码器的输出特征图。
在其中，
复杂度随特征图的空间大小呈线性增长。
在自注意力模块中，对象查询相互交互，以捕获它们之间的关系。
query 和 key 元素都是对象查询。
其中，N q = N k = N，自注意力模块的复杂度为O（2N C 2 + N 2 C）。
对于中等数量的对象查询，复杂性是可以接受的。
DETR 是一种吸引人的目标检测设计，它消除了对许多手工设计的组件的需求。
但是，它也有自己的问题。
这些问题主要归因于Transformer在处理图像特征图作为关键要素时注意力的不足：（1）DETR在检测小物体方面的性能相对较低。
现代物体检测器使用高分辨率特征图来更好地检测小物体。
然而，高分辨率特征图会导致DETR的Transformer编码器中的自注意力模块具有不可接受的复杂度，该模块与输入特征图的空间大小具有二次复杂度。
（2）与现代目标探测器相比，DETR需要更多的训练周期才能收敛。
这主要是因为处理图像特征的注意力模块很难训练。
例如，在初始化时，交叉注意力模块在整个特征图上几乎是平均注意力。
同时，在训练结束时，注意力地图被学习为非常稀疏，只关注对象
4 方法

4.1 用于端到端物体检测的可变形变压器

可变形注意力模块。
在图像特征图上应用 Transformer 注意力的核心问题是它会查看所有可能的空间位置。
为了解决这个问题，我们提出了一个可变形的注意力模块。
受可变形卷积的启发（Dai et al.， 2017;Zhu et al.， 2019b） ，可变形注意力模块只关注参考点周围的一小群关键采样点，而不管特征图的空间大小如何，如图 2 所示。通过为每个查询只分配少量固定数量的键，可以缓解收敛性和特征空间分辨率的问题。

给定一个输入特征图 x ∈ R C×H×W，设 q 索引一个具有内容特征 z q 和二维参考点 p q 的查询元素，可变形的注意力特征计算公式为
其中 m 索引注意头，k 索引采样键，K 是总采样键数 （K HW）。
∆p mqk 和 A mqk 分别表示第 m 个注意力头中第 k 个采样点的采样偏移量和注意力权重。
标量注意力权重 A mqk 位于 [0， 1] 范围内，归一化为 K k=1 A mqk = 1。
∆p mqk ∈ R 2 是具有无约束范围的二维实数。
由于 p q + ∆p mqk 是分数的，因此在计算 x（p q +∆p mqk） 时应用了双线性插值，如 Dai 等人 （2017） 。
∆p mqk 和 A mqk 都是通过在查询特征 z q 上的线性投影获得的。
在实现中，查询特征 z q 被馈送到 3M K 通道的线性投影算子，其中前 2M K 通道编码采样偏移量 ∆p mqk，其余的 M K 通道被馈送到 softmax 算子以获得注意力权重 A mqk 。
可变形注意力模块设计用于将卷积特征图作为关键元素进行处理。
设N q为查询元素的数量，当M K相对较小时，可变形注意力模块的复杂度为O（2N q C 2 + min（HW C 2 ， N q KC 2 ）） （详见附录A.1）。
当它应用于 DETR 编码器时，其中 N q = HW ，复杂度变为 O（HW C 2 ），其复杂度与空间大小呈线性关系。
当它作为 DETR 解码器中的交叉注意力模块应用时，其中 N q = N（N 是对象查询的数量），复杂度变为 O（N KC 2 ），这与空间大小 HW 无关。
多尺度可变形注意力模块。
大多数现代目标检测框架都受益于多尺度特征图（Liu et al.， 2020）。
我们提出的可变形注意力模块可以自然地扩展到多尺度特征图。
设 {x l } L l=1 为输入多尺度特征图，其中 x l ∈ R C×H l ×W l 。
设 pq ∈ [0， 1] 2 为各查询元素 q 的参考点归一化坐标，则应用多尺度可变形注意力模块作为
其中 M 索引注意头，L 索引输入特征级别，K 索引采样点。
∆p mlqk 和 A mlqk 分别表示第 l 个特征层次和第 m 个注意力头中第 k 个采样点的采样偏移量和注意力权重。
标量注意权重 A mlqk 由下式归一化
在这里，我们使用归一化坐标 pq ∈ [0， 1] 2 来提高尺度公式的清晰度，其中归一化坐标 （0， 0） 和 （1， 1） 分别表示图像的左上角和右下角。
公式 3 中的函数 φ l （ pq ） 将归一化坐标 pq 重新缩放到第 l 级的输入特征图。
多尺度可变形注意力与之前的单尺度版本非常相似，不同之处在于它从多尺度特征图中采样LK点，而不是从单尺度特征图中采样K点。
当L = 1， K = 1， W m ∈ R Cv×C被固定为单位矩阵时， 所提出的注意力模块将退化为可变形卷积 （Dai et al.， 2017）。
可变形卷积是为单刻度输入设计的，只关注每个注意力头的一个采样点。
然而，我们的多尺度可变形注意力会观察来自多尺度输入的多个采样点。
所提出的（多尺度）可变形注意力模块也可以看作是Transformer注意力的一种有效变体，其中可变形采样位置引入了预滤波机制。
当采样点遍历所有可能的位置时，所提出的注意力模块等效于变压器注意力。
可变形变压器编码器。
我们用提出的多尺度可变形注意力模块替换了 DETR 中处理特征图的 Transformer 注意力模块。
编码器的输入和输出都是具有相同分辨率的多尺度特征图。
在编码器中，我们从ResNet（He et al.， 2016）中C 3到C 5阶段的输出特征图中提取多尺度特征图{x l } L-1 l=1 （L = 4）（通过1 × 1卷积变换），其中C l的分辨率比输入图像低2 l。
最低分辨率的特征图 x L 是通过在最后 C 5 阶段的 3 × 3 步长 2 卷积获得的，表示为 C 6。
所有多尺度特征图的 C = 256 个通道。
请注意，FPN中的自上而下结构（Lin et al.， 2017a）没有被使用，因为我们提出的多尺度可变形注意力本身可以在多尺度特征图之间交换信息。
附录A.2也说明了多尺度特征图的构建。第 5.2 节中的实验表明，添加 FPN 不会提高性能。

在编码器中应用多尺度可变形注意力模块时，输出为与输入分辨率相同的多尺度特征图。
键元素和查询元素都是来自多尺度特征图的像素。
对于每个查询像素，引用点都是其自身。
为了确定每个查询像素位于哪个特征级别，除了位置嵌入之外，我们还向特征表示添加了一个尺度级嵌入，表示为 e l 。
与固定编码的位置嵌入不同，尺度级嵌入{e l } L l=1是随机初始化并与网络联合训练的。
可变形变压器解码器。
解码器中有交叉注意力和自注意力模块。
这两种类型的注意力模块的查询元素都是对象查询。
在交叉注意力模块中，对象查询从特征图中提取特征，其中关键元素是编码器的输出特征图。
在自注意力模块中，对象查询相互交互，其中关键元素是对象查询。
由于我们提出的可变形注意力模块是为将卷积特征图作为关键元素进行处理而设计的，因此我们仅将每个交叉注意力模块替换为多尺度可变形注意力模块，而保持自注意力模块不变。
对于每个对象查询，参考点 pq 的二维归一化坐标是通过可学习的线性投影后跟 sigmoid 函数从其对象查询嵌入中预测的。
由于多尺度可变形注意力模块提取参考点周围的图像特征，我们让检测头将边界框预测为相对于参考点的相对偏移量，以进一步降低优化难度。
参考点用作箱体中心的初始猜测。
检测头预测相对于参考点的相对偏移量。
有关详细信息，请参阅附录 A.3。
这样，学习到的解码器注意力将与预测的边界框具有很强的相关性，这也加速了训练收敛。
通过在DETR中用可变形注意力模块替换Transformer注意力模块，建立了一个高效、快速的收敛检测系统，称为Deformable DETR（见图1）。
4.2 可变形 DETR 的其他改进和变体

Deformable DETR 为我们利用端到端目标检测器的各种变体开辟了可能性，这要归功于其快速收敛、计算和内存效率。
由于篇幅有限，我们这里只介绍这些改进和变体的核心思想。
实施详情载于附录A.4。
迭代边界框细化。
这是受到光流估计中开发的迭代细化（Teed & 邓，2020）的启发。
我们建立了一种简单有效的迭代边界框细化机制，以提高检测性能。
在这里，每个解码器层都根据上一层的预测来优化边界框。
两级可变形DETR。
在原始 DETR 中，解码器中的目标查询与当前图像无关。
受两阶段目标检测器的启发，我们探索了一种可变形 DETR 的变体，用于生成区域建议作为第一阶段。
生成的区域建议将作为对象查询输入解码器以进行进一步细化，形成一个两阶段的可变形 DETR。
在第一阶段，为了实现高召回率提案，多尺度特征图中的每个像素都将作为一个对象查询。
然而，直接将目标查询设置为像素，会给解码器中的自注意力模块带来不可接受的计算和内存成本，其复杂度随着查询次数的增加呈二次增长。
为了避免这个问题，我们去掉了解码器，并形成了一个仅限编码器的可变形 DETR，用于区域提案生成。
在其中，每个像素都被分配为一个对象查询，该查询直接预测边界框。
得分最高的边界框被选为区域提案。
在将区域提案提交到第二阶段之前，不应用 NMS。
5 实验

数据。
我们在COCO 2017数据集上进行了实验（Lin等人，2014）。
我们的模型在火车集上训练，并在 val 集和 test-dev 集上进行评估。
实施细节。
ImageNet（邓等人，2009）预训练的ResNet-50（He et al.，2016）被用作消融的骨干。
多尺度特征图是在没有FPN的情况下提取的（Lin等人，2017a）。
默认情况下，M = 8 和 K = 4 设置为可变形的注意力。
可变形 Transformer 编码器的参数在不同的功能级别之间共享。
其他超参数设置和训练策略主要遵循DETR（Carion et al.， 2020），不同之处在于边界框分类采用损失权重为2的Focal Loss（Lin et al.， 2017b），对象查询数量从100个增加到300个。
我们还报告了 DETR-DC5 与这些修改的性能，以便进行公平比较，表示为 DETR-DC5 +。
默认情况下，模型训练了 50 个 epoch，学习率在第 40 个 epoch 处衰减了 0.1 倍。
继 DETR （Carion et al.， 2020） 之后，我们使用 Adam 优化器（Kingma & Ba， 2015）训练模型，基本学习率为 2 × 10 -4，β 1 = 0.9，β 2 = 0.999，权重衰减为 10 -4。
用于预测对象查询参考点和采样偏移量的线性投影的学习率乘以 0.1 因子。
运行时间在 NVIDIA Tesla V100 GPU 上评估。
5.1 与DETR的比较

如表1所示，与Faster R-CNN + FPN相比，DETR需要更多的训练周期才能收敛，并且在检测小物体时性能较低。
与 DETR 相比，Deformable DETR 以更少的训练周期获得更好的性能（尤其是在小物体上），训练周期少 10×。
详细的收敛曲线如图 3 所示。
借助迭代边界框细化和两阶段范式，该方法可以进一步提高检测精度。
我们提出的可变形 DETR 与 Faster R-CNN + FPN 和 DETR-DC5 相当。
但运行速度比 DETR-DC5 快得多 （1.6×），仅比 Faster R-CNN + FPN 慢 25%。
DETR-DC5的速度问题主要是由于Transformer关注的内存访问量大。
我们提出的可变形注意力可以缓解这个问题，但代价是内存访问是无序的。
因此，它仍然比传统的卷积略慢。
5.2 可变形注意力的消融研究

表2显示了所提出的可变形注意力模块的各种设计选择的烧蚀。
使用多尺度输入代替单刻度输入可以有效提高1.7% AP的检测精度，特别是对于2.9% AP S的小物体。
增加采样点数量K可以进一步提高0.9%的AP。
使用多尺度可变形注意力，允许不同尺度水平之间的信息交换，可以带来额外的1.5%的AP改善。
由于已经采用了跨级特征交换，因此添加 FPN 不会提高性能。
当未应用多尺度注意力且 K = 1 时，我们的（多尺度）可变形注意力模块退化为可变形卷积，从而提供明显较低的精度。
5.3 与最先进方法的比较

表3将所提出的方法与其他最先进的方法进行了比较。
我们在表3中的模型都使用了迭代边界框细化和两阶段机制。
使用ResNet-101和ResNeXt-101（Xie等人，2017），我们的方法分别实现了48.7 AP和49.0 AP，没有花里胡哨。
通过使用 ResNeXt-101 和 DCN（Zhu 等人，2019b），精度提高到 50.1 AP。
通过额外的测试时间增强，所提出的方法实现了52.3 AP。
表 2：COCO 2017 val set 上可变形注意力的消融。
“MS 输入”表示使用多刻度输入。
“MS 注意力”表示使用多尺度可变形注意力。
K 是每个特征级别上每个注意力头的采样点数。
MS 输入 MS 注意 K FPNs AP AP50 AP75 APS APM APL 4 FPN （Lin et al.， 2017a） 43.8 62.6 47.8 26.5 47.3 58.1 4 BiFPN （Tan et al.， 2020） 43.9 62.5 47.7 25.6 47.4
6 结论

Deformable DETR 是一种端到端的目标检测器，高效且快速收敛。
它使我们能够探索更有趣和实用的端到端目标检测器变体。
Deformable DETR的核心是（多尺度）可变形注意力模块，是处理图像特征图的一种高效注意力机制。
我们希望我们的工作为探索端到端目标检测开辟了新的可能性。
A 附录

A.1 可变形注意力的复杂度 假设查询元素的数量为 N q ，在可变形注意力模块（见公式 2）中，计算采样坐标偏移量 ∆p mqk 和注意力权重 A mqk 的复杂度为 O（3N q CM K）。
给定采样坐标偏移和注意力权重，计算公式 2 的复杂度为 O（N q C 2 + N q KC 2 + 5N q KC），其中 5N q KC 中 5 的因子是由于双线性插值和注意力的加权和。
另一方面，我们也可以在抽样前计算 W m x，因为它与查询无关，计算方程 2 的复杂度将变为 O（N q C 2 +HW C 2 +5N q KC）。
因此，可变形注意力的总复杂度为 O（N q C 2 + min（HW C 2 ， N q KC 2 ） + 5N q KC + 3N q CM K）。
在我们的实验中，M = 8，K ≤ 4，C = 256，因此 5K + 3M K < C，复杂度为 O（2N q C 2 + min（HW C 2 ， N q KC 2 ））。
A.2 为可变形DETR构建多尺度特征图

如第 4.1 节所述并如图 4 所示，编码器 {x l } L-1 l=1 （L = 4） 的输入多尺度特征图是从 ResNet 中阶段 C 3 到 C 5 的输出特征图中提取的 （He et al.， 2016） （通过 1×1 卷积转换）。
最低分辨率的特征图 x L 是通过在最后 C 5 阶段的 3 × 3 步长 2 卷积获得的。
请注意，FPN（Lin et al.， 2017a）没有被使用，因为我们提出的多尺度可变形注意力本身可以在多尺度特征图之间交换信息。
其中 d ∈ {1， 2， ...， D}， ∆b d q{x，y，w，h} ∈ R 在第 d 个解码器层预测。
不同解码器层的预测头不共享参数。
初始框设置为 b0 qx = pqx、b0 qy = pqy、b0 qw = 0.1 和 b0 qh = 0.1。
该系统对 b 0 qw 和 b 0 qh 的选择具有鲁棒性。
我们尝试将它们设置为 0.05、0.1、0.2、0.5，并取得了类似的性能。
为了稳定训练，类似于 Teed & 邓 （2020） ，梯度仅通过 ∆b d q{x，y，w，h} 反向传播，并在 σ -1 （ bd-1 q{x，y，w，h} 处被阻塞。
在迭代边界框细化中，对于第d个解码器层，我们对从（d -1）-th解码器层预测的框bd-1 q相关的关键元素进行采样。
对于第d个解码器层的交叉注意力模块中的公式3，（ bd-1 qx ， bd-1 qy ）作为新的参考点。
采样偏移量 ∆p mlqk 也受盒子大小的调节，如 （∆p mlqkx bd-1 qw ， ∆p mlqky bd-1 qh ）。
此类修改使采样位置与先前预测的框的中心和大小相关。
两级可变形DETR。
在第一阶段，给定编码器的输出特征图，将检测头应用于每个像素。
检测头分别为用于边界框回归的 3 层 FFN 和用于边界框二元分类（即前景和背景）的线性投影。
设 i 从特征级别 l i ∈ {1， 2， ...， L} 索引一个像素，二维归一化坐标 pi = （p ix ， piy ） ∈ [0， 1] 2 ，其对应的边界框由 bi 预测
其中，基本对象尺度 s 设置为 0.05，则 ∆b i{x，y，w，h} ∈ R 由边界框回归分支预测。
DETR 中的匈牙利损失用于训练检测头。
给定第一阶段预测的边界框，将选择得分最高的边界框作为区域提案。
在第二阶段，这些区域建议作为迭代边界框细化的初始框输入解码器，其中对象查询的位置嵌入被设置为区域建议坐标的位置嵌入。
多尺度可变形注意力的初始化。
在我们的实验中，注意力头的数量设置为 M = 8。
在多尺度可变形注意力模块中，W m ∈ R Cv×C 和 W m ∈ R C×Cv 是随机初始化的。
用于预测 A mlqk 和 ∆p mlqk 的线性投影的权重参数初始化为零。
对线性投影的偏置参数进行初始化，使
对于迭代边界框细化，将解码器中用于 ∆p mlqk 预测的初始化偏置参数进一步乘以 1 2K ，使得初始化时的所有采样点都在从前一个解码器层预测的相应边界框内。
A.5 DETR 查看什么 DEFORMABLE DETR？

为了研究Deformable DETR通过什么给出最终的检测结果，我们绘制了最终预测中每个项目的梯度范数（即物体中心的x/y坐标、物体边界框的宽度/高度、该物体的类别分数）相对于图像中每个像素的梯度范数，如图5所示。
根据泰勒定理，梯度范数可以反映输出相对于像素的扰动会发生多大的变化，因此它可以向我们展示模型主要依赖于哪些像素来预测每个项目。
可视化表明，Deformable DETR 查看对象的极值点以确定其边界框，这类似于 DETR 中的观察结果（Carion et al.， 2020）。
更具体地说，Deformable DETR 关注对象的 x 坐标和宽度的左/右边界，以及 y 坐标和高度的顶部/底部边界。
同时，与 DETR （Carion et al.， 2020） 不同，我们的可变形 DETR 还查看对象内部的像素以预测其类别。
A.6 多尺度可变形注意力的可视化

为了更好地理解学习到的多尺度可变形注意力模块，我们在编码器和解码器中可视化了最后一层的采样点和注意力权重，如图 6 所示。
为了便于阅读，我们将来自不同分辨率的特征图的采样点和注意力权重合并到一张图片中。
与 DETR （Carion et al.， 2020） 类似，实例已经在 Deformable DETR 的编码器中分离。
在解码器中，我们的模型专注于整个前景实例，而不是像 DETR 中观察到的那样只关注极值点（Carion et al.， 2020）。
结合图 5 中 ∂c ∂I 的可视化，我们可以猜测原因是我们的可变形 DETR 不仅需要极值点，还需要内部点来确定对象类别。
可视化还表明，所提出的多尺度可变形注意力模块能够根据前景物体的不同尺度和形状调整其采样点和注意力权重。
第 l 个特征级别的输入特征图的宽度 A 第 q 个查询的第 q 个键在第 m 个头处的第 k 个键的 mqk 注意力权重 第 q 个查询对第 m 个头处的第 l 个特征级别的第 k 个键的 mqk 注意力权重 z q 第 q 个查询的第 q 个查询的第 q 个参考点的 q 2-d 参考点的参考点的 q 二维坐标对于第 q 个查询 x 个输入特征图（关键元素的输入特征） x k 第 k 个键的输入特征 x l 个特征级别的输入特征图 ∆P MQK 第 Q 个查询到第 M 个头处的第 K 个键的采样偏移量 ∆P MLQK 第 Q 个查询到第 L 个键的第 K 个键的采样偏移量，在第 M 个头处 W m 处的输出投影矩阵第 m 个头 U m 输入查询投影矩阵 第 m 个头 V m 输入键 第 m 个头的投影矩阵 W m 个头的输入值投影矩阵 第 m 个头 φ l （ p） l 个特征级别 exp 指数函数的 p 的未归一化二维坐标 σ S 形结肠函数 σ -1 反 S 形结肠函数

A.7 符号

图 1：所提出的可变形 DETR 物体检测器的图示。
;Child等人（2019）;Huang 等人（2019 年）;Ho 等人（2019 年）;Wang等人（2020a）;胡等人（2019）;Ramachandran et al. （2019））仍然仅限于第一类。

尽管理论上降低了复杂性，但 Ramachandran 等人（2019 年）;胡等（

图 2：所提出的可变形注意力模块的图示。
图3：可变形DETR和DETR-DC5在COCO 2017 val集上的收敛曲线。
对于可变形的 DETR，我们通过改变学习率降低的时期（AP 分数跳跃的地方）来探索不同的训练计划。
图 4：为 Deformable DETR 构建多尺度特征图。
屋宇 署
图 5：最终检测结果中每个项目的梯度范数（物体中心坐标 （x， y）、物体边界框的宽度/高度 w/h、该物体的类别得分 c）相对于输入图像 I 中每个像素的梯度范数。
可变形 DETR 与 COCO 2017 val set 上的 DETR 的比较。
DETR-DC5 + 表示 DETR-DC5，具有焦点损失和 300 个对象查询。
可变形 DETR 与 COCO 2017 测试开发集上最先进方法的比较。
“TTA”表示增强，包括水平翻转和多尺度测试。
在论文中查找符号的查找表。
