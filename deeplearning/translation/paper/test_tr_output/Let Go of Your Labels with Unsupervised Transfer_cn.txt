通过无监督传输放开标签

基础视觉语言模型已经实现了预训练表示在广泛的下游任务中的显著零样本可转移性。
然而，为了解决一项新任务，零样本传输仍然需要人工指导来定义数据中出现的视觉类别。
在这里，我们展示了在搜索数据集的标签时，会出现完全无监督转移，该数据集在不同基础模型的表示空间中诱导出最大边距分类器。
我们提出了 TURTLE，这是一种完全无监督的方法，它有效地利用这一指导原则来揭示下游数据集的底层标记，而无需任何监督和特定于任务的表示学习。
我们在包含 26 个数据集的多样化基准套件上评估了 TURTLE，并表明它实现了新的最先进的无监督性能。
此外，TURTLE虽然是完全无监督的，但在广泛的数据集上都优于零样本转移基线。
特别是，TURTLE 通过采用相同的表示空间，跨越广泛的架构和模型大小，匹配了 CLIP 零样本在 26 个数据集上的平均性能。
通过使用两个基础模型的表示空间来指导对底层标签的搜索，TURTLE超越了零样本转移和无监督提示调优基线，展示了无监督转移的惊人力量和有效性。
1. 引言

迁移学习是一种基本的机器学习范式，它利用深度 * 等贡献 1 EPFL，瑞士洛桑的大规模预训练。
通信地址：Maria Brbić <mbrbic@epfl.ch>.
第 41 届机器学习国际会议论文集，维也纳，奥地利。PMLR 235,2024 年。

版权所有 2024 作者。
神经网络可以提高资源有限的下游任务的模型性能（Pan&Yang，2009）。
早期的迁移学习方法依赖于对整个模型的监督微调来解决感兴趣的下游任务（Kolesnikov 等人，2020 年）。
近期工作（He et al.， 2022;Li et al.， 2022;周等， 2022;Oquab 等人，2023 年;Darcet 等人，2024 年）表明，与在冻结的预训练骨架（即线性探针）之上训练线性分类器相比，在传输过程中微调整个模型只会带来边际收益。

尽管这些方法消除了对特定任务表示进行微调的需要，但它们仍然需要每个类至少几个标记的示例，以便在下游任务上实现人类水平的性能。
最近，基础模型（Bommasani et al.， 2022）已经出现，在零样本设置下接近人类水平的智能，可以完成各种任务。
特别是，Radford et al. （2021） 提出了 CLIP，它通过在联合嵌入空间中对齐图像及其相应的标题来训练表示。
在预训练之后，通过嵌入数据中出现的视觉类别的描述来构建零样本分类器。
后续工作成功地采用了这种表示学习原理，在其他领域实现了零样本传输，例如音频信号处理（Elizalde et al.， 2023a; b） 、生物医学 （Lin et al.， 2023;Robinson et al.， 2023） 和符号回归 （Meidani et al.， 2024） 。

尽管基础模型取得了显著的成功，但零样本转移仍然需要人工指导来解决一项新任务。
但是，基础模型的表示能否用于以完全无监督的方式解决新任务？
无监督传输的最简单方法是在预训练表示之上应用现成的聚类方法（MacQueen，1967）。
然而，与（弱）监督和零样本转移相比，这种策略不可避免地导致性能急剧下降（周等人，2022 年;Oquab 等人，2023 年）。

最近，Gadetsky & Brbić （2023） 引入了 HUME，这是一种无监督学习框架，用于从预训练的表示中推断给定数据集的底层人类标签。
虽然与无监督基线相比，HUME取得了卓越的性能，但它仍然需要特定于任务的代表-图1。下游转移的类型在可用监管的数量上有所不同。

给定基础模型的表示空间，（i）监督传输，表示为线性探针，在给定下游数据集的标记示例的情况下训练线性分类器;（ii） Zero-shot Transfer 假设给出了下游数据集中出现的视觉类别的描述，并通过文本编码器使用它们来解决任务;（iii）无监督转移假设可用的监督量最少，即仅给出类别的数量，旨在揭示数据集的底层人工标记。

怨恨学习，并不能缩小无监督转移和零样本转移之间的差距。
在这里，我们介绍了 TURTLE，一种能够从基础模型进行无监督转移的方法。
我们方法背后的关键思想是搜索下游数据集的标记，该数据集在单个或多个基础模型的空间中最大化线性分类器的边际，以揭示潜在的人类标记。
与零样本和监督传输相比，TURTLE的无监督传输不需要任何形式的监督（图1）。
与深度聚类方法相比（Xie et al.， 2016;Chang 等人，2017 年;Caron 等人，2018 年;Van Gansbeke 等人，2020 年;Niu et al.， 2022） ， TURTLE 不需要针对特定任务的表示学习，这对于现代基础模型来说是昂贵的。

我们研究了 TURTLE 在涵盖 26 个数据集和 7 个不同基础模型的广泛评估套件上的性能。
我们将 TURTLE 与各种基线进行比较，这些基线在下游转移的可用监管量方面有所不同。
首先，与最近最先进的无监督基线相比，TURTLE在所有考虑的数据集上都优于这些基线，从而设定了新的最先进的无监督性能。
与零样本传输相比，使用两个基础模型实例化的 TURTLE 在所有研究的模型大小上都超过了 CLIP 零样本传输，在研究的数据集上实现了高达 35% 的卓越绝对改进。
在相同的单一表示空间下，TURTLE 在 8 种研究模型架构中的 7 种上与 CLIP 零样本传输的性能非常匹配。
特别是，使用相同模型大小和表示空间的最佳 TURTLE 模型在 26 个数据集中的 13 个数据集上优于 CLIP 零样本。
最后，与线性探针表示的监督转移相比，TURTLE 在 26 个研究数据集中的 5 个上接近其性能，这表明当给出足够高质量的表示时，可能不需要标签来推断潜在的人类标签。
2. 背景

在本节中，我们将介绍无监督传输的问题设置，并概述我们构建的关键概念。
无人看管的传输。
设 X ⊆ R d 为输入空间，D = {x n } N n=1 ， x n ∈ X 为 由 N 个样本和 C 类组成的数据集，其中 C 是先验已知的。
设 φ（x） ： X -→ R q 表示从输入空间 X 到预训练基础模型的 q 维表示空间的映射。
我们想要回答的问题是，如何利用基础模型的表示，以完全无监督的方式解决新任务。
因此，通过无监督转移，我们考虑了在没有任何监督的情况下推断数据集 D 的底层人类标记 1 的任务，给定基础模型的表示。
基于泛化的人类标记学习。
Gadetsky & Brbić （2023） 最近引入了一个基于泛化的目标，该目标评估线性模型在从预训练模型获得的表示之上的泛化能力。
该目标的动机是线性模型在许多人类标记任务的表示空间中的强大泛化能力。
有了这种洞察力，目标是找到这样的标记，以优化线性模型在给定数据集的所有可能标记上的泛化能力。
标记的质量是通过线性模型对给定标记定义的任务进行概括的能力来衡量的。
具体而言，设 τ ： X -→ {1， . . .
，C}表示数据集的标注函数。
设 f （x） = w T φ（x） 表示基础模型的表示空间 φ（x） 中的线性模型。
给定一个训练-检验分裂 （D tr ， D te ），可以在训练分裂 D tr 上训练模型，并带有标记 τ （D tr ） 和分类损失函数 L 以获得 f 。
经过训练后，可以通过计算f on D te的误差来评估模型的泛化能力。
因此，基于泛化的目标定义如下：
其中，对数据集 D 的所有可能标记集执行最小化。这导致了一个困难的离散优化问题。

为了克服这一限制，Gadetsky & Brbić （2023） 将离散标签 τ 的最小化 w.r.t. 替换为最小化 w.r.t.
任务编码器的连续参数 θ τ θ （x） ： X -→ ∆ C-1 ，其中 ∆ C-1 表示 （C -1）-维概率单纯形。
因此，仔细设计 τ θ 变得至关重要，因为它定义了基于泛化的目标 （1） 所探索的搜索空间。
休谟框架。
该框架的实例化在 HUME （Gadetsky & Brbić， 2023） 中提出，在表示空间 ψ（x） 中使用线性模型对 τ θ 进行建模，该模型是通过在目标数据集 D 上进行自监督预训练获得的：
其中 σ ： R -→ ∆ C-1 表示激活函数。
这种建模选择对应于将（1）中的搜索空间限制为一组标签，这些标签在表示空间ψ（x）中是线性可分离的。
此外，获取ψ（x）需要特定任务的表示学习，即在目标数据集D上运行自监督学习。由于可靠的自监督预训练需要大量数据（Wang & Isola，2020），这阻止了在资源有限的下游任务上成功的无监督转移。

给定任务编码器参数化 τ HUME θ ，HUME 优化了以下目标以搜索底层的人类标签：
其中 L ce 是交叉熵损失函数，f approx 是使用迭代优化算法获得的 f 的近似解。
休谟诉诸迭代微分（Domke，2012;Shaban et al.， 2019） 来解决由此产生的双水平优化问题，导致昂贵的整体训练过程。

3. 基于泛化的目标分析

为了理解（1）中提出的基于泛化的目标的归纳偏差，我们在二元标记τ（x）： X → {-1， +1}的情况下考虑该目标，指数损失函数L exp （f （x）， τ （x）） = exp（-τ （x）f （x））。
为了简化分析，我们假设任务编码器 τ θ 是相同表示空间 φ（x） 的线性模型，即 τ θ （x） = σ（θ T φ（x）），其中 σ ： R -→ [-1; 1] 是一个奇数激活函数，例如 tanh。
这相当于将（1）中的搜索空间限制为一组标签，这些标签在表示空间φ（x）中是线性可分离的。
此外，我们不区分训练分裂和检验分裂，即 D tr = D te = D。我们在本节末尾的评论中对上述假设进行了详细讨论。

为了得到f的近似解，我们使用迭代优化算法。
具体来说，设 w m+1 = Ξ（w m ， D） 表示优化算法的一步，即 Ξ（w m ， D） = w m -η∇ w x∈D L（w T m φ（x）， τ θ （x）） 用于步长为 η 的梯度下降。
类似地，设 w M = Ξ （M ） （w 0 ， D） 表示从 w 0 开始的优化算法的 M 步。
最终，上述规范导致了以下双层优化问题：
我们把（4）和（5）分别称为内在目标和外在目标。
我们的主要结果背后的关键观察结果是，内部优化 （5） 对应于可分离数据上的非正则化逻辑回归，使我们能够采用 Soudry 等人 （2018） 的开创性结果。
这项工作表明，当应用于非正则化逻辑回归任务时，梯度下降输出的迭代偏向于最大边距超平面的方向。
显然，任务编码器 τ θ 生成了 D 的标签，根据定义，这些标签在表示空间 φ（x） 中是线性可分的。
因此，对于给定的标记 τ θ，w M 将遵循 max-margin 超平面的方向。
反过来，要观察的最后一点是，代入 （4） 中的迭代，当 w M 相对于 τ θ 具有较大的边距 τ θ （x）w T M φ（x） 时，外部目标最小化。
有了这种直觉，我们现在准备陈述我们的主要结果：命题 3.1。
给定 M ≫ 1，θ ̸ = 0 和确保收敛的适当步长 η，则
哪里
以 lim M →∞ ∥r M （θ）∥ 2 = 0 为界，w SVM （θ） 是给定 θ 的硬边距 SVM 的解：
我们将证明推迟到附录 A。该结果表明，基于泛化的目标上限是拟合到标签τθ的硬边际SVM的范数。

因此，最小化 L 二进制 M 将不可避免地导致最小化相对于标签的范数（即最大化边距）。
因此，优化过程将产生具有相应分类器大边距的标签。
总体而言，我们的研究结果表明，被监督学习算法广泛采用的最大边距原则（Vapnik， 1995）表现为基于泛化的目标的归纳偏差（1）。
备注 3.2.
（搜索空间限制）。
当 τ θ 生成的标签在表示空间 φ（x） 中线性可分时，上述结果成立。
这一假设导致了对具有受限搜索空间的基于泛化的目标（1）的分析。
Ji & Telgarsky （2019） 表明，在不可分离标记的情况下，梯度下降反映了可分离的情况，遵循数据的最大线性可分离子集的最大边距方向。
因此，可以预期，在完整的搜索空间上优化的基于泛化的目标（1）的下界继承了这些属性，反映了可分离的情况。
备注3.3.
（训练-测试拆分假设）。
基于泛化的目标 （1） 假设分别在内外水平上存在不同的训练-检验分裂 （D tr ， D te），以获得模型 f 真实风险的无偏估计。
在我们的分析中，我们简化了这个假设，并在两个层面上都使用了D。
我们的结果表明，在这种情况下，最小化基于泛化的目标会导致线性模型相对于 D 上的标记 τ 的裕量最大化。反过来，这将不可避免地导致保留数据的低误差，因为边距大小上限泛化误差（Bartlett & Shawe-Taylor，1999;Gronlund 等人，2020 年）。

备注3.4.
（渐近分析）命题 3.1 是相当非正式的，因为它取代了梯度下降迭代 w M 到外部目标的渐近行为。

尽管需要对残差进行严格的分析才能确定准确的边界，但这些结果有助于掌握为推断人类标签而设计的基于泛化的物镜中包含的归纳偏差。
总之，该结果表明，优化基于泛化的目标（1）产生的标签会在表示空间φ（x）中诱导出最大边距分类器。
我们的主要成果深受开创性著作的启发（Soudry et al.， 2018;Ji & Telgarsky， 2019 ）揭示了梯度下降对最大边距解的隐性偏差。

同样，我们证明了基于泛化的目标 （1） 鼓励标记 τ，这样，如果随后在表示空间 φ（x） 中训练最大边距分类器以拟合标签 τ，则获得的边距将在所有可能的标签上最大。
4. TURTLE框架

这些见解为我们提供了开发 TURTLE 的指导原则，TURTLE 是一个在给定基础模型表示的情况下进行高效完全无监督传输的通用框架。
优化目标。
命题 3.1 对基于泛化的目标 （1） 中包含的归纳偏差提供了重要的见解。
事实上，人们可以通过最大化线性模型相对于标签的边距来搜索底层的人类标签。
突破这一原则的极限，我们建议通过在多个基础模型的空间中同时最大化线性模型的边距来搜索标签。
给定 K 个基础模型，设 φ k （x） 是第 k 个基础模型的表示空间。
给定由任务编码器 τ θ 定义的标签，设 w k M 是经过训练的第 k 个线性模型，以在 k （x） 的表示空间中拟合此标签φ。
那么，TURTLE的优化目标如下：
其中，Ξ M （w k 0 ， D） 表示从 w k 0 开始运行的 M 步的迭代优化算法 Ξ。
直观地说，损失函数中的 K 项中的每一个都鼓励 τ θ 在相应的表示空间 φ k 中最大化第 k 个线性模型的裕量。
与HUME的目标（3）相反，HUME的目标（3）仅在单个空间ψ（x）中最大化边距，TURTLE为搜索过程提供了更有效的指导。
任务编码器参数化。
任务编码器 τ θ 的参数化定义了标签的搜索空间，因此它对优化过程具有至关重要的意义。
在 TURTLE 中，我们采用基础模型的预训练表示空间来定义任务编码器 τ θ 。
在整个训练过程中，这些表示保持固定，从而减轻了对特定任务表示学习的需求。
具体来说，给定 K 表示空间 φ k （x），我们定义任务编码器 τ θ 如下：
哪里
使得 θ = {θ 1 ， . . .
， θ K } 表示所有可训练参数，σ 是 softmax 激活函数。
训练后，将像往常一样计算集群分配：
其中 τ TURTLE θ （x） c 表示将样本 x 分配给第 c 个聚类的概率。
相较于（2）中的HUME框架在自监督表示空间ψ（x）中仅在所有线性可分离标签上搜索底层的人类标签，TURTLE的参数化极大地扩展了搜索空间。
事实上，将 τ θ 建模为一个简单的集合可以诱导出搜索空间，该搜索空间至少是基础模型的每个表示空间中所有线性可分离标签的并集 φ 1 ， . .
， φ K .
可以进一步建议采用更深层次的架构来建模 τ θ ，但是这种建模选择可能会导致捕获数据中虚假相关性的任务，并且不一定反映人类标记（Atanov 等人，2022 年）。
因此，我们的设计选择有效地增加了搜索空间，并通过采用基础模型的强表示来缓解对特定任务微调的需求。
正规化。
任务编码器可以合成退化标签，即将所有样本分配给一个类（Gadetsky & Brbić，2023）。
尽管此类标记在所有表示空间中诱导出具有最大可能边距的线性分类器，但它们是无关紧要的。
为了避免这种微不足道的解决方案，我们分别对任务编码器的每个术语进行正则化：
哪里
最终目标函数。
将 （ 8 ） 和 （ 11 ） 放在一起，TURTLE 最终优化了以下目标函数：
我们发现 γ = 10 是熵正则化强度γ的一个很好的默认选择。
我们在附录 G 中展示了此超参数的鲁棒性。
高效优化。
新的基于优化的目标（8）是一个具有凸内部分的双能级优化问题。
事实上，给定 τ θ ，计算 w k M 对应于 D 上的逻辑回归问题，在第 k 个表示空间 φ k 中标记 τ θ （D）。
使用基于梯度的技术学习参数 θ 涉及计算总导数 d dθ L TURTLE M ：
哪里
∂θ 是雅可比式，在实践中计算成本高昂（Domke，2012 年;Shaban 等人，2019 年）。

关键的观察结果是，在内层和外层水平上都使用同一组样本 D 可以让我们丢弃总导数的第二项。
事实上，经过训练 2020 年）在实践中，该估计器在类似于我们的双层优化问题中表现出了强大的性能。
TURTLE的伪代码在算法B1中提供，实现细节在附录B.3中提供。
5. 实验

5.1. 实验装置

数据集和评估指标。
我们研究了 TURTLE 在 26 个视觉数据集的广泛基准上的性能（Radford 等人，2021 年）。
附录 B.1 中提供了每个数据集的详细说明。
我们使用准确性指标将我们的框架与基线进行比较，并采用匈牙利算法（Kuhn，1955）将TURTLE（10）找到的标记与相应数据集的地面实况标记进行匹配。
默认情况下，我们在相应数据集的训练分割上训练 TURTLE，并在测试分割上提供结果。
在附录 H 中，我们还表明，模仿部署制度，即仅将测试拆分用于训练，不会导致 TURTLE 的性能下降。
TURTLE 中的基础模型。
我们采用 CLIP （Radford et al.， 2021） 表示，它们跨越不同的架构和模型大小，特别是 5 种不同的 ResNet（R50、R101、R50x4、R50x16 和 R50x64）和 3 种不同的视觉转换器（ViT-B/32、ViT-B/16 和 ViT-L/14）。
如果 TURTLE 仅使用单个空格 CLIP 表示（K = 1 in （ 8 ） 和 （ 9 ）），我们将 TURTLE 称为 TURTLE 1-space。
如果 TURTLE 使用两种不同的基础模型，我们将它称为 TURTLE 2 空间。
也就是说，我们使用 DINOv2 ViT-g/14（Oquab 等人，2023 年）作为第二个空间，而第一个空间始终用 CLIP 变体之一表示。
因此，为了在使用两个表示空间（例如 ViT-L/14）时指定特定的 CLIP 架构，我们将 TURTLE 称为 TURTLE 2 空间 ViT-L/14。
我们预先计算了整个基准测试的所有表示，并在整个训练过程中保持这些表示的固定。
附录 B.2 中提供了所用模型的详细说明和用于准备表示的其他规格。
基线。
我们将使用 TUR-TLE 的无监督转移与它们使用的监督量不同的基线进行比较（图 1）。
首先，我们将 TURTLE 与 HUME 进行比较（Gadetsky & Brbić，2023 年），这种方法最近显示出最先进的无监督学习性能，并超越了传统的深度聚类方法（Van Gansbeke 等人，2020 年;Niu et al.， 2022;Amrani 等人，2022 年;Feng 等人，2023 年）。

接下来，为了探索我们在无监督传输方面能走多远，我们将具有挑战性的环境中的 TURTLE 与零样本传输、无监督提示调整和有监督基线进行了比较。
与完全无人监督的 TURTLE 相比，所有这些基线都使用某种形式的监督。
我们首先将 TURTLE 与 CLIP 零样本传输（Radford 等人，2021 年）进行比较，后者采用对地面实况类别的描述作为监督的一种形式。
继（Radford et al.， 2021）之后，我们执行提示工程和组装，为每个数据集构建一个零样本分类器。
作为更强大的基线，我们将 TURTLE 与最先进的无监督提示调优方法 UPL （Huang et al.， 2022）、POUF （Tanwisuth et al.， 2023） 和 GDA （Wang et al.， 2024） 进行了比较。
这些方法通过对下游任务的无监督适应来增强由 CLIP 零样本分类器定义的类原型。
最后，我们在 CLIP 表示之上采用监督线性探针作为监督传输基线。
表1突出显示了转移类型之间的差异。
C2 ），为清楚起见，省略。
与零样本转移的比较。
我们将 TUR-TLE 与 CLIP 零样本传输进行了比较，后者使用对地面实况类别的描述作为监督的一种形式。
值得注意的是，在不使用任何监督的情况下，TURTLE 2-spaces 在不同 ViT 骨干网的 26 个基准数据集中大大优于 CLIP 的零样本传输（图 4）。
ViT-B/32号文件

特别是ViT：在ViT-B/32、ViT-B/16和ViT-L/14主干上，TURTLE 2空间的绝对改善分别比CLIP zeroshot高出9%、7%和4%（相对改善17%、12%和5%）。
此外，在所有研究的 ViT 模型中，即使是 TURTLE 1 空间也与 CLIP 零样本的性能相匹配。
需要注意的是，CLIP 零样本和 TURTLE 1 空间都是同一表示空间中的线性模型，仅在可用于生成权重的监督量上有所不同。
在比较单个数据集的性能时，TURTLE 在 26 个数据集中的 15 个数据集上优于 CLIP 零样本传输，在 EuroSAT、MNIST 和 Flowers102 数据集上分别获得了 35%、21% 和 20% 的显着绝对增益（图 5）。
我们在附录 D 中提供了所有 TURTLE 和 CLIP 零样本变体的单独分数。
与无监督提示调优的比较。
接下来，我们将 TURTLE 与无监督提示调优基线进行比较。
我们遵循以前的工作，并将 CLIP ResNet-50 表示用于所有方法。
尽管完全不受监督，但TURTLE的表现始终大大优于所有考虑的基线（表2）。
具体来说，与最佳无监督提示调优基线相比，TUR-TLE 在平均准确度方面实现了 8% 的绝对提高（12% 的相对改进）。
在 Flowers102 和 EuroSAT 数据集上，我们的框架分别获得了 27% 和 41% 的绝对收益（相对改善 37% 和 75%）。
总体而言，这些结果表明了无监督转移的惊人效果。
与监督转移的比较。
最后，我们将 TURTLE 1 空间 ViT-L/14 与相同表示空间中的监督线性探针进行比较。
这意味着在这种设置中，两种模型在 CLIP ViT-L/14 的表示空间中都是线性的，仅在用于产生权重的监督量上有所不同。
监督线性探针使用所有可用标签进行训练。
因此，我们可以假设它代表了无监督迁移可以实现的最大迁移学习性能。
我们观察到无监督传输性能与其完全监督传输性能之间存在 0.87 （p 值 < 10 -8） 的高正相关关系（图 6）。
这一结果表明，随着监督线性探针性能的提高，TURTLE的性能也可能提高，我们将在后面的段落中进一步研究。
值得注意的是，TURTLE 在 STL10、CIFAR10、Flowers102、Food101 和 Hateful-Memes 上接近“最佳”转移性能，这表明当给出足够高质量的表示时，可能不需要标签，如监督线性探针所测量的那样。
我们对 TURTLE 2 空间进行了类似的分析，并观察到更强的相关性，从而减小了 TURTLE 2 空间和监督线性探针之间的差距（图 E2）。
在ImageNet上消融不同表示空间。

上一段的结果推测，纳入更有力的表述可能会导致无监督转移的性能提高。
为了验证这一点，我们在ImageNet-1000数据集上运行具有不同表示空间对的TURTLE（邓等人，2009）。
图 7 中的结果表明，无监督传输性能与监督线性探针测量的表征质量之间存在 0.74 （p 值 < 10 -8） 的正相关关系。
获得的结果证实，对给定数据集采用更强的表示可以提高 TURTLE 的性能。
因此，TURTLE 可以通过利用基础模型开发中的持续进展来进一步提高性能。
此外，鉴于TURTLE的准确性与基于泛化的目标之间存在高度的正相关关系（图B1），TURTLE可以用作代理，在没有下游任务标签的情况下测量给定表示的质量。
虚线 y = x 表示“最佳”无监督传输。
TURTLE和监督线性探针的性能表现出很强的相关性（ρ = 0.87，p = 6.3×10 -9的双侧Pearson相关系数）。
在 5 个数据集上，TURTLE 接近“最佳”无监督传输的性能（≤ 3 分差）。
六、相关工作

（弱）监督转移。
（弱）监督转移方法至少需要一定程度的监督才能执行下游转移。
例如，BigTransfer（Kolesnikov 等人，2020 年）表明，在大规模预训练后对整个模型进行有监督的微调可以成功地在完全监督和少样本制度下转移知识。
自我监督学习的最新进展（He et al.， 2022;Li et al.， 2022;周等， 2022;Oquab 等人，2023 年;Darcet 等人，2024 年）已经证明，与微调整个模型相比，线性探针足以实现有竞争力的性能。

尽管这些方法很有优势，但它们需要标记的样本来执行下游转移。
零样本传输。
CLIP 等基础模型（Radford et al.， 2021）最近实现了零样本转移，它仅依赖于一组人类指令，例如出现在数据中的视觉类别描述，而不是一组标记示例。
尽管零样本转移在不同领域取得了成功（Elizalde et al.， 2023a;Lin 等人，2023 年;Robinson 等人，2023 年;Meidani et al.， 2024） ，收集零样本注释仍然需要专业的领域知识，这在许多实际应用中可能很难获得。

与零样本转移方法相比，TURTLE实现了完全无监督的转移，有效地缓解了对任何人工指导的需求。
深度聚类。
深度聚类方法（Xie et al.， 2016;Chang 等人，2017 年;Caron 等人，2018 年;Van Gansbeke 等人，2020 年;Niu et al.， 2022） 旨在联合在目标数据集上进行深度表示学习和聚类。

最近最先进的方法（Van Gansbeke 等人，2020 年;Niu et al.， 2022） 依赖于耗时的三阶段程序，分别涉及自监督表示学习、聚类和通过自标记进行微调。

与深度聚类方法相比，TURTLE 通过采用预训练基础模型的表示空间，减轻了对费力的特定于任务的表示学习的需求。
此外，与严重依赖图像增强来诱导语义有意义的聚类的深度聚类方法相比，TURTLE 建立在开创性的最大边距原则之上，该原则可以毫不费力地应用于图像数据模态之外。
因此，我们的方法提供了一种高效且有效的方法来执行基础模型的完全无监督转移。
最大边距聚类。
我们的研究表明，优化 Gadetsky & Brbić （2023） 中提出的基于泛化的目标会导致寻找一种标签，该标签可以在数据集的所有可能标签上最大化最大边距分类器的边距。
首次尝试采用最大边距原则进行聚类可以追溯到最大边距聚类（MMC）（Xu et al.， 2004）。
后来的工作将这个框架扩展到多类聚类（Xu & Schuurmans， 2005;Wang等，2010），多视图聚类（Zhao et al.，2009），或专注于提高可扩展性（Zhang et al.，2007;Wang et al.， 2010） 。

与采用高效一阶梯度优化技术的TURTLE相比，上述方法依赖于昂贵的离散优化技术。
此外，每种方法都以自己的方式采用最大边距原则，以实现多类或多空间场景，而 TURTLE 为任意数量的类和表示空间提供了统一的框架。
优化算法的隐性偏差。
理解优化算法的隐性偏差在现代机器学习中起着至关重要的作用。
Soudry等人（2018）的开创性研究表明，当应用于可分离数据的非正则化逻辑回归任务时，梯度下降会收敛到最大边际超平面的方向，而没有明确强制执行这种边际最大化。
后来，Ji & Telgarsky （2019）扩展了分析，并展示了在不可分离数据的情况下类似的梯度下降行为。
在我们的工作中，我们采用上述发现来研究基于泛化的目标的归纳偏差。
令人惊讶的是，我们发现它产生的标签使最大边距分类器相对于标签的边距最大化。
因此，这种洞察力使我们能够开发 TURTLE，这是一种在给定基础模型表示的情况下实现完全无监督转移的方法。
7. 结论

在这项工作中，我们已经证明，基础模型的表示可以用来以完全无监督的方式解决新任务。
我们方法背后的关键见解是寻找一种标签，该标签在基础模型的表示空间中诱导出最大边距分类器。
我们利用这一洞察力来开发 TURTLE，这是一个基于不同基础模型表示的有效无监督传输的通用框架。
通过广泛的评估，我们发现 TURTLE 在完全无监督的情况下，与零样本传输相比，仅使用单一表示空间即可实现有竞争力的性能。
此外，与零样本传输相比，利用额外的表示空间可以带来显著的收益。
鉴于我们框架的灵活性，研究结果还表明，TURTLE可以通过利用未来出现的新的更强大的基础模型来提供更好的无监督传输性能。
影响声明

尽管我们工作的主要目标是推进机器学习领域，但所提出的框架依赖于基础模型的表示空间。
这些模型继承了嵌入在它们接受训练的数据中的偏见（Bommasani 等人，2022 年）。
因此，在将 TURTLE 部署到医学等关键用例时，建议进行广泛的评估和调整。
A. 命题 3.1 的证明
在这里，我们首先提供了Soudry等人（2018）的主要结果的简化版本，以确保完整性，然后提出了命题3.1的证明。
为了清楚起见，我们重载了 x n 的表示法，并认为 x n 已经在表示空间 φ（x） 中表示，即 x n = φ（x n ）。
给定数据集的二元标记函数 τ （x） ∈ {-1， +1} D = {x n } n n=1 ，设 L（w） 为指数损失函数：
我们考虑使用梯度下降最小化 （ 14 ） 步长 η：
设 w SVM 表示硬边距 SVM 问题的原始解：
让 SVM 表示硬边距 SVM 问题的双重解决方案α SVM ：
其中原始变量和对偶变量相关为 （Vapnik， 1995） 。
假设 A.2.（非退化数据集）支持向量 S = {x n ∈ D|τ （x n ）w T SVM x n = 1} 跨度数据，即 rank（D S ） = rank（D），其中 D S 是一个矩阵，其列为 x n ∈ S。此外，对于每个 x n ∈ S，相应的对偶变量严格为正，即 （α SVM ） n > 0，其余为零。

在上述规范之后，Soudry等人（2018）的开创性结果的简化版本为： Soudry等人（2018）对于几乎所有线性可分的非简并（假设A.2）数据集（假设A.1），任何起点w 0和步长η <1/L（w 0）），梯度下降迭代（15）将表现为：
其中 w SVM 是最大边距向量 （ 16 ），w 是以下项的解：
残差 R M 与 LiM M→∞ ∥R M 为界 ∥ 2 = 0
根据这个结果，我们分析了基于泛化的目标：
其中 τ θ （x） = σ（θ T x） 是具有奇数激活函数（如 tanh 和 w） 的任务编码器 M = Ξ （M ） （w 0 ， D） 表示梯度下降的 M 步长，步长为 η，标记由 τ θ 定义。
在不失去普遍性的情况下，我们可以假设 ∥x n ∥ 2 ≤ 1，∀x n ∈ D。鉴于上述规格，我们现在准备陈述我们的主要结果：

命题A.4.（基于泛化的目标的下限）根据命题 A.3 的假设，给定 M ≫ 1 且 θ ̸ = 0，我们有：

其中 g（θ） = （M η exp（∥r M （θ）∥ 2 ）） -1 ，残差 r M （θ） 与 lim M →∞ ∥r M （θ）∥ 2 = 0 为界，w SVM （θ） 是给定 θ 的硬边距 SVM 的解：
证明。
关键的观察结果是，任务编码器 τ θ （x） 生成线性可分离的标签，使我们能够应用命题 A.3 并将迭代 w M 的显式形式替换到外部目标 （20） 中。
实际上，例如，w * = θ 满足假设 A.1，即 τ θ （x n ）θ T x n > 0 对于所有 x n ∈ D 和 θ ̸ = 0。因此，将迭代 w M 代入外部目标会导致：

其中我们明确指出 w SVM （θ）、w（θ） 和 r M （θ） 取决于任务编码器 τ θ 的参数 θ 。
设 L n （θ） 为总和的第 n 项，S θ 为支持向量的索引，即 n ∈ {1， . . .
， N } s.t.
τ θ （x n ）w T SVM x n = 1.
然后，由于 exp（•） 的非负性，我们有：
考虑单项 L n （θ）， n ∈ S θ 并打开括号，我们得到：
分别检查 （ 26 ） 每个项 L i ， 我们得到：
η （ 19 ）;（iii） L 3 ≥ exp（-∥r M （θ）∥ 2 ） 由柯西-施瓦茨不等式给出，给定 ∥τ θ （x n ）x n ∥ 2 ≤ 1。将其与（25）相结合，最后我们得到：

其中最后一个相等来自以下事实：
结束证明。
B. 实验细节

B.1. 数据集

我们在 Radford 等人 （2021） 研究的 26 个视觉数据集上评估了我们的框架。
这些数据集涵盖了广泛的视觉任务，包括通用的物体分类数据集 CIFAR10 （Krizhevsky & Hinton， 2009） ， CIFAR100 （Krizhevsky & Hinton， 2009） ， STL10 （Coates et al.， 2011） ， ImageNet （邓 et al.， 2009 ）， Caltech101 （Fei-Fei et al.， 2004） ;细粒度对象分类数据集 Food101 （Bossard et al.， 2014） ， Flowers （Nilsback & Zisserman， 2008） ， Birdsnap （Berg et al.， 2014） ， Stanford Cars （Krause et al.， 2013） ， FGVC Aircraft （Maji et al.， 2013） ， Oxford Pets （Parkhi et al.， 2012） ;手写数字分类数据集MNIST（LeCun et al.， 1998）;纹理分类数据集DTD （Cimpoi et al.， 2014） ;场景分类数据集SUN397（Xiao et al.， 2016）;面部情感识别数据集FER2013 （Goodfellow et al.， 2015） ;卫星图像分类数据集EuroSAT （Helber et al.， 2019） ， RESISC45 （Cheng et al.， 2017） ;德国交通标志识别基准 （GTSRB） （Stallkamp et al.， 2012） ;KITTI距离数据集（Geiger等人，2012）;转移组织分类数据集 PatchCamelyon （PCam） （Veeling et al.， 2018） ;动作识别数据集 UCF101 （Soomro et al.， 2012） ， Kinetics700 （Carreira et al.， 2019） ;CLEVR计数数据集（Johnson等人，2017）;仇恨模因数据集（Kiela et al.， 2020）;国家分类数据集 Country211 （Radford et al.， 2021） 和 Rendered SST2 数据集 （Radford et al.， 2021）。

对于 CLEVR，我们取 2000 个随机样本作为训练分割，500 个随机样本作为检验分割。
对于两个视频数据集 UCF101 和 Kinetics700，我们将每个视频片段的中间帧作为预训练模型的输入。
表 B1 中提供了每个数据集的详细信息。
我们使用准确性作为所有数据集的评估指标。
最后，值得注意的是，如果预训练的表示可用，TURTLE也可以应用于除视觉以外的各种模态任务，甚至可以应用于跨模态场景的任务。
表 B1 .
包含 26 个数据集的基准测试套件。
我们使用准确性作为所有数据集的评估指标。
数据集 类数量 训练大小 测试大小 食物101 （Bossard et al.， 2014） 101 75,750 25,250 CIFAR10 （Krizhevsky & Hinton， 2009） 10 50,000 10,000 CIFAR100 （Krizhevsky & Hinton， 2009） 100 50,000 10,000 Birdsnap （Berg et al.， 2014） 500 37,221 2,500 SUN397 （Xiao et al.， 2016） 397 19,850 19,850 StanfordCars （Krause et al.， 2013） 196 8,144 8,041 FGVC 飞机 （Maji et al.， 2013） 100 6,667 3,333 DTD （Cimpoi et al.， 2014） 47 3,760 1,880 OxfordPets （Parkhi et al.， 2012） 37 3,680 3,669 Caltech101 （Fei-Fei et al.， 2004） 102 3,060 6,084 Flowers （Nilsback et al.， 2008） 102 2,040 6,149 MNIST （LeCun et al.， 1998） 10 60,000 10,000 FER2013 （Goodfellow et al.， 2015） 7 28,709 3,589 STL10 （Coates et al.， 2011） 10 5,000 8,000 EuroSAT （Helber et al.， 2019） 10 10,000 5,000 RESISC45 （Cheng et al.， 2017） 45 25,200 6,300 GTSRB （Stallkamp et al.， 2012） 43 26,640 12,630 KITTI 距离 （Geiger et al.， 2012） 4 5,985 1,496 Country211 （Radford et al.， 2021） 211 42,200 21,100 PatchCamelyon （Veeling et al.， 2018） 2 294,912 32,768 UCF101 （Soomro et al.， 2012） 101 9,537 3,783 Kinetics700 （Carreira et al.， 2019） 700 536,485 33,966 CLEVR 计数 （Johnson et al.， 2017） 8 2,000 500 HatefulMemes （Kiela et al.， 2020） 2 8,500 500 The Render SST2 （Radford et al.， 2021） 2 7,792 1,821 ImageNet （邓 et al.， 2009） 1000 1,281,167 50,000

B.3. 实施细节

高效的交替优化。
TURTLE 包含一个双层目标，该目标使用在任务编码器生成的任务上训练的线性分类器的训练损失来测量任务编码器的损失。
任务编码器的超梯度为 ∇ θ L = ∂L ∂θ + （ ∂w ∂θ ） T ∂L ∂w |w=w * ，其中雅可比 ∂w ∂θ 通常获得成本高昂。

现有研究通常基于隐函数定理通过展开或近似来估计超梯度，例如，参见Finn et al. （2017） ;Lorraine 等人 （2020） ;Ji et al. （2021） ;Kwon 等人 （2023） ;Dagréou 等人 （2022） ;Bolte 等人 （2023） ;Liu等人（2022）。

然而，这些方法在实践中可能是低效和次优的（Scieur 等人，2022 年）。
幸运的是，在 TURTLE 框架中，鉴于 ∂∂∂∂∂L ∂w |w=w * ≈ 0.因此，任务编码器的梯度简化为 ∇ θ L = ∂L ∂θ |w=w * .

这启发了我们通过交替优化来训练任务编码器，这已被证明对最小-最小优化问题有效（Ablin et al.， 2020）。
在每次迭代中，我们首先固定任务编码器并训练线性分类器进行 M 步长，以找到其近似最优值。
请注意，可以选择每次（冷启动）重新初始化线性分类器，或者仅从上次迭代的值（热启动）开始，这可能会引入不同的隐式偏差，正如 Vicol 等人 （2022） 所指出的那样。
之后，我们根据线性分类器的损失来更新任务编码器。
训练是有效的，因为在这个过程中不需要二阶梯度。
TURTLE的伪代码在算法B1中提供。
算法 B1 TURTLE 用于无监督迁移 1： 输入：数据集 D，类数 C，迭代次数 T，表示空间 φ 1 （•）， ...， φ K （•），任务参数 θ = {θ 1 ， ...， θ K }， 线性分类器 w 1 ， ...， w K ， 学习率 η， 优化算子 Ξ（•），适应步骤数 M ， 熵正则化权重 γ // Ξ（•） 可以是任意迭代算子， 例如，梯度下降 2：随机初始化 θ 1 ， ...， θ K 和 w 1 0 ， ...， w K 0 3： 对于 t = 1 到 T do 4：

数据集 X ∼ D 的样本小批量
5:

从任务编码器生成任务
如果是热启动，则更新起始点 ∀k ∈ [K]， w k 0 ← w k M // 冷启动保持初始 w k 0 9： end for 10： 输出： 任务参数 θ = {θ 1 ， ...， θ K } 训练详情。
我们在训练之前预先计算所有数据集的特征表示。
我们使用权重归一化（Salimans&Kingma，2016）来参数化任务编码器，因为我们发现它有助于收敛。
ADAM（Kingma&Ba，2015）优化器用于线性分类器和任务编码器的训练。
我们使用 10000 作为默认的批处理大小。
对于小于 10000 的数据集，我们在每次迭代时都使用全批量训练模型。
总体而言，我们发现 TURTLE 对批量大小的选择具有鲁棒性。
我们更新线性分类器，在每次迭代中 M = 10 步，并训练任务编码器，总共 T = 6000 次迭代。
如果没有特别提及，我们将所有实验的熵正则化参数设置为 γ = 10。
我们在附录 G 中展示了 TURTLE 对此超参数的鲁棒性。
对于每个数据集，我们对任务编码器和线性分类器的 5 种不同学习率进行网格搜索，η ∈分别为 {0.01， 0.005， 0.001， 0.0005， 0.0001}。
我们将每对学习率与热启动或冷启动的选择相结合，最后得到一组 50 个三元组来搜索每个数据集。
我们使用交叉验证来选择超参数，如下所述。
继 Gadetsky & Brbić （2023） 之后;Van Gansbeke et al. （2020） ，我们使用匈牙利算法（Kuhn， 1955）来匹配 TURTLE 找到的标记和真值标记来计算聚类精度。

如果未指定，我们将在训练拆分上训练模型，并在测试拆分上报告聚类准确性。
在 H 部分中，我们还考虑了在测试拆分上设置训练和评估 TURTLE，模仿低数据制度。
任务选择的交叉验证。
对于每个数据集，我们在网格搜索后得到 50 个任务，即每个任务对应于超参数三元组。
我们使用 10 倍交叉验证来选择最佳任务。
交叉验证将学习的任务视为“伪标签”，并测量在这些“伪标签”上训练的线性分类器的泛化误差。
具体来说，我们将数据集随机分成 10 个折。
在每一轮中，线性分类器在 9 个折叠上进行训练，并在其余折叠上进行测试。
最终的交叉验证分数是所有轮次的平均测试准确度。
重要的是，此过程仅依赖于学习的任务，不需要有关地面实况标签的任何信息。
对于在多个表示上训练的 TURTLE，我们分别对每个表示空间进行交叉验证，并平均最终分数。
交叉验证分数最高的任务被选为 TURTLE 的最终输出。
图 B1 显示了 TURTLE、2 格、CLIP、ViT-L/14 和 DINOv2 获得的学习任务的性能及其在 26 个数据集上的相应交叉验证分数。
如图所示，交叉验证分数与聚类精度密切相关，在 26 个数据集上，双侧 Pearson 相关系数平均为 ρ = 0.61。
此外，在 20 个数据集中，交叉验证成功识别出最佳或接近最佳的任务（即聚类准确度差异小于 1.5 分）。
交叉验证的结果还实证验证了基于泛化的目标的有效性，并表明泛化误差低的标记往往更符合人类标记任务，证实了Gadetsky&Brbić（2023）在广泛的数据集上的原始发现。
线性探头。
监督线性探针是一种广泛使用的方法，用于评估表征学习的质量（Radford 等人，2021 年;Oquab 等人，2023 年）。

它根据从预训练模型中提取的表示在火车分裂上训练线性分类器，然后评估测试分裂上的性能。
在我们的论文 3 中，我们使用 cuML.LogisticRegression （Raschka et al.， 2020） 进行线性探针评估。
线性分类器使用 L-BFGS 优化器进行最多 1000 次迭代的训练。
cuML 库允许 GPU 加速，因此它比 sklearn.linear 快得多
型。LogisticRegression 对应物，尤其是在 ImageNet 等大型数据集上。

为了确定 L2 范数正则化的强度，我们随机抽取训练分裂的 20% 进行验证，并在从 10 -6 到 10 6 的对数空间中搜索 96 个值。
在小型数据集上，选择过程需要几分钟，在 ImageNet 上，使用单个 NVIDIA A100 GPU 时，选择过程大约需要 8 小时。
之后，我们在整个训练分割上训练具有最佳正则化强度的模型，并在测试分割上报告分类精度。
C. 关于无监督基线和数值结果的详细情况

K 均值聚类。
我们在预训练特征之上应用K-Means（MacQueen，1967）聚类作为不需要特定任务表示学习的简单基线。
与线性探针类似，我们还使用 CuML 库中的实现进行 GPU 加速（即 CuML.KMeans）。
对于每个数据集和相应的表示，我们在训练分裂上用最多 1000 次迭代 （max iter=1000） 和 10 次随机初始化 （n init=10） 训练 K-Means，并在测试分裂上报告聚类精度。
在使用多个表示的情况下，我们首先对每个预训练模型的 L2 归一化表示，然后在所有 L2 归一化特征的串联之上应用 K-Means 聚类。
休谟。
HUME （Gadetsky & Brbić， 2023） 是最近最先进的无监督学习基线，它引入了基于泛化的目标的实例化 （3）。
具体来说，它通过学习目标数据集上特定于任务的表示来对任务编码器进行建模，然后测量线性分类器在基础模型的表示空间中的泛化误差。
我们使用原始源代码 4 来实现 HUME，并进行了修改以提高速度和性能。
特别是，我们用预训练的基础模型替换了特定于任务的表示，因为我们从经验上发现它产生了更好的性能。
此外，我们去除了原始HUME中使用的方差减少，并在每次迭代中仅对单个小批量（即与TURTLE相同）进行采样，因为我们发现它显着降低了计算成本并且不会影响最终性能。
我们在每次迭代中以 M = 300 步更新线性分类器，并以总共 T = 6000 次迭代来训练任务编码器。
默认批处理大小设置为 10000。
此外，我们遵循与TURTLE相同的超参数选择程序来选择HUME的内部/外部学习率和热启动/冷启动。
TURTLE 与 HUME 和 K-Means 的比较。
为了公平比较，我们使用相同的表示空间训练 TURTLE、HUME 和 K-Means，即 CLIP ViT-L/14 和 DINOv2 ViT-g/14。
鉴于 HUME 的任务编码器参数化仅使用单个空间，我们使用 CLIP 或 DINOv2（分别表示为 HUME CLIP 和 HUME DINOv2）建模的任务编码器运行 HUME，并使用其余表示空间测量泛化误差。
对于每种方法，我们以分钟为单位报告训练时间，并在 3 个随机种子上平均分配聚类精度。
对于每个随机种子，我们执行 HUME 和 TURTLE 的超参数选择，如上面相应的小节所述。
表 C1 和表 C2 显示了在 5 个数据集上获得的结果。
总体而言，结果表明，TURTLE在所有考虑的数据集上都优于HUME和K-Means，凸显了TURTLE中设计选择的有效性。
例如，与 HUME 相比，在 TURTLE 中结合多个表示空间来对任务编码器进行建模带来了可观的收益。
也就是说，在MNIST数据集上，TURTLE比HUME DINOv2和HUME CLIP分别实现了28%和23%的绝对改善（40%和30%的相对改善）。
此外，TURTLE 中使用的高效一阶优化技术允许快速优化，即使在 ImageNet 等大规模数据集上也只需 5 分钟。
E. 26个视觉数据集的额外结果

我们在表D1中显示了在26个视觉数据集上使用线性探针的监督转移、CLIP零样本转移和TURTLE无监督转移的所有实验结果。
DINOv2 ViT-g/14 的线性探针性能也包括在内，以供参考。
如表所示，TURTLE在各种数据集和模型上都实现了强大的无监督传输性能。
例如，如图 E1 所示，TURTLE 1 空间 CLIP ViT-L/14 在 26 个数据集中的 13 个上超过了相应的 CLIP 零样本传输。
当使用多种表示进行训练时（即使用 CLIP 模型和 DINOv2 ViT-g/14），与 TURTLE 1 空间相比，TURTLE 2 空间在大多数数据集上都取得了卓越的性能。
值得注意的是，在MNIST和CIFAR100等数据集上，绝对提升分别为31%和21%，表明TURTLE在结合多个基础模型知识方面的有效性。
此外，如图 5 所示，使用 CLIP ViT-L/14 和 DINOv2 ViT-g/14 训练的 TURTLE 在 26 个数据集中的 15 个数据集上优于 CLIP 零样本。
此外，我们在图 6 中使用单一表示空间比较了 TURTLE 与有监督线性探针的性能。
可以看出，无监督转移与有监督线性探针的性能之间存在很强的正相关关系。
图 E2 提供了使用 CLIP ViT-L/14 和 DINOv2 ViT-g/14 训练的 TURTLE 2 空间的分析，表明 TURTLE 2 空间的性能也与平均线性探针性能密切相关。
总体而言，这些结果表明，TURTLE可能会从监督线性探针测量的表征质量的提高中受益。
最后，值得注意的是，在某些数据集上，TURTLE 2 空间的性能可能低于 TURTLE 1 空间，如表 D1 所示。
我们假设这种差异可能源于 DINOv2 表示对于与语义理解密切相关的任务的次优性，例如语义分析（Render SST、HatefulMemes）、交通标志识别 （GTSRB）、地理位置 （Country211） 和对象计数 （CLEVR）。
由于 DINOv2 是用自监督目标进行预训练的（Oquab et al.， 2023），因此学习到的特征可能无法直接转移到这些语义密集型任务。
线性探针的性能也可以观察到这种趋势，其中CLIP ViT-L/14在Rendered SST2、CLEVR、Country211、GTSRB和FER2013上的性能大大优于DINOv2 ViT-g/14。
因此，合并 DINOv2 表示可能无法为这些特定数据集产生最佳结果。
G. 不平衡数据集和熵正则化

继 Xu et al. （2004）;Van Gansbeke 等人 （2020） ;Gadetsky & Brbić （2023） ，我们使用熵正则化 （11） 来防止任务编码器产生微不足道的解决方案，即将所有样本分配给单个类。

默认情况下，我们将所有实验的正则化强度设置为 γ = 10。
请注意，（11）的最优解是为每个类生成一个样本数量相等的标签。
但是，某些数据集不是类平衡的。
在这种情况下，强熵正则化可能会损害学习过程。
为了理解熵正则化的影响，我们分别在不平衡数据集（Birdsnap、FER2013、GTSRB、KITTI、HatefulMemes）和其余 21 个平衡数据集上展示了 TURTLE 的平均性能，γ ∈ {0， 1， 3， 5， 10} 在图 G1 中。
结果表明，熵正则化通常是有帮助的，因为 η = 0 可能会导致微不足道的解决方案。
此外，对于平衡数据集，TURTLE 对正则化超参数的选择具有鲁棒性。
而对于不平衡的数据集，正确选择正则化参数可以进一步提高性能。
H. TURTLE 在测试拆分中进行训练和评估

在之前的实验中，我们在训练分裂 D tr 上训练 TURTLE，并在测试分裂 D ter 上评估聚类精度。
在本节中，为了研究 TURTLE 在低数据状态下的性能，我们在直接在测试拆分上训练和评估 TURTLE 时考虑设置。
图 H1 比较了在 D tr 上训练的 TURTLE 和在 D te 上训练的 TURTLE 在 26 个数据集上的性能。
这两个设置都在测试拆分时进行评估。
如图所示，在 26 个数据集中的 24 个数据集中，在 D te 上训练的 TURTLE 在 26 个数据集中取得了与 TURTLE 几乎相同的性能，但 Caltech101 和 Flowers102 除外。
我们发现这种差异可能归因于这样一个事实，即 Caltech101 和 Flowers102 的训练分配平衡，但测试分配不平衡。
总体而言，结果表明，TURTLE不需要大量数据即可成功执行无监督传输。
图2.TURTLE 的表现优于无监督基线。

TURTLE 与无监督基线在准确性方面的比较。
所有方法都使用 CLIP、ViT L/14 和 DINOv2 表示。
条形图表示平均性能，在三次运行中计算出标准偏差。
图4.TURTLE 在给定基础模型的表示空间的情况下实现无监督转移。

TURTLE 采用相同的 CLIP 表示空间，在 26 个数据集上平均与相应的 CLIP 零样本分类器的性能非常匹配。
通过使用额外的表示空间，TURTLE 的性能优于零样本迁移，展示了无监督迁移学习的卓越能力。
图5.
TURTLE 在 26 个数据集中的 15 个数据集上优于 CLIP 零样本分类器。
TURTLE 使用 CLIP、ViT-L/14 和 DINOv2 表示进行训练。
CLIP zero-shot 采用相同的 CLIP ViT-L/14 架构。
此外，我们观察到，即使只有一个 CLIP 表示空间，TURTLE 在 13/26 数据集上的表现也优于 CLIP（图 E1）。
图6.
TURTLE的无监督传输性能与有监督线性探针的性能相关。
虚线 y = x 表示“最佳”无监督传输。
TURTLE和监督线性探针的性能表现出很强的相关性（ρ = 0.87，p = 6.3×10 -9的双侧Pearson相关系数）。
在 5 个数据集上，TURTLE 接近“最佳”无监督传输的性能（≤ 3 分差）。
图7.上图：ImageNet-1000 数据集上用于 7 个不同表示空间的监督线性探针。

底部：热图表示 TURTLE 在 ImageNet-1000 上的无监督性能。
次级对角线单元格对应于 TURTLE 1 空间，而非对角线单元格则引用 TURTLE 2 空间，并具有一对相应的表示空间。
TUR-TLE的性能与监督线性探针的性能呈强正相关（ρ = 0.74，p = 1.4 × 10 -9的双侧Pearson相关系数）。
图 B1.
通过交叉验证选择任务。
我们使用 TURTLE 2 格、CLIP、ViT-L/14 和 DINOv2 来生成任务。
我们展示了 TURTLE 学习的任务的交叉验证分数和相应的聚类准确性，每个数据集有 50 个不同的超参数。
交叉验证分数与聚类准确度密切相关（26 个数据集上平均的双侧 Pearson 相关系数 ρ = 0.61）。
图 E1.
使用相同的表示空间，TURTLE 在 26 个数据集中的 13 个上优于 CLIP 零样本分类器。
TURTLE 使用 CLIP ViT-L/14 进行训练，不需要任何监督。
CLIP zero-shot 使用相同的架构，但需要额外的文本编码器和视觉类别的描述。
图 E2.
无监督迁移学习性能与有监督线性探针性能相关。
TURTLE 2空间的性能与使用CLIP ViT-L/14和DI-NOv2 ViT-g/14的线性探针的平均性能密切相关（ρ = 0.88，p = 2.3 × 10 -9，双侧Pearson相关系数）。
图 G1.
熵正则化的消融。
我们展示了不同熵正则化强度下类不平衡数据集（Birdsnap、FER2013、GTSRB、KITTI、HatefulMemes）和类平衡数据集（其余 21 个数据集）的平均性能。
图 H1.
在 26 个数据集中的 24 个数据集中，在测试拆分中训练的 TURTLE 获得了与在训练拆分中训练的 TURTLE 相似的性能。
结果都是在测试拆分中评估的。
Caltech101 和 Flowers102 的差异是因为它们在训练分割上是平衡的，但在测试分割上是不平衡的。
所考虑的下游传输类型之间的差异。
我们请读者参阅附录 B.3，了解我们的模型选择程序的详细说明。
代码在 https://github.com/mlbio-epfl/turtle 上公开提供。
TURTLE 2 空间的性能优于无监督提示调优方法。ZS 列指示方法是否利用零样本监督进行预测。所有方法均采用 CLIP ResNet-50 表示。TURTLE 还使用 DINOv2 表示作为第二个表示空间。方法：ZS，宠物，鲜花，FGVC，DTD，EuroSAT，汽车，食品，SUN，加州理工学院，UCF，ImageNet，平均值。

TURTLE 和无监督基线的准确性。
使用在 3 次运行中计算的标准偏差对结果进行平均。
TURTLE 和无监督基线的训练时间（以分钟为单位）。
使用在 3 次运行中计算的标准偏差对结果进行平均。
K-Means 和 TURTLE 的标准差可以忽略不计。
